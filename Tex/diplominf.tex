\documentclass[hyperref,german,diplominf,final,lof,lot,twoside]{cgvpub}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig

\usepackage{lmodern}
%\usepackage[ngerman]{babel}
\usepackage{microtype}

\author{Josef Schulz}
\title{Optimierung und Übertragung von Tiefengeometrie für Remote-Visualisierung}
\birthday{20. Oktober 1989}
\placeofbirth{Naumburg (Saale)}
\matno{3658867}
\betreuer{Dr. rer. nat. Sebastian Grottel}
\bibfiles{literatur}

\problem{
In Big-Data-Szenarien in der Visualisierung spielt der Ansatz der Remote-Visualisierung eine zunehmende Rolle.  
Moderne Netzwerktechnologien bieten große Datenübertragungsraten und niedrige Latenzzeiten. Für die 
interaktive Visualisierung sind aber selbst kleinste Latenzzeiten problematisch. Um diese vor dem Benutzer maskieren zu können, kann eine Extrapolation der Darstellung durchgeführt werden. 
Diese Berechnungen erfordern zusätzlich zum normalen Farbbild weitere Daten, beispielsweise 
ein Tiefenbild und die Daten der verwendeten Kameraeinstellung.
Für die Darstellungsextrapolation werden Farb- und Tiefenbild zusammen interpretiert, beispielsweise als Punktwolke oder Höhenfeldgeometrie. 
Im Rahmen dieser Arbeit soll untersucht werden, wie die Darstellung mittels Höhenfeldgeometrie optimiert  werden kann. 
Ansätze sind hierfür Algorithmen aus der Netzvereinfachung. Zu erwarten sind sowohl 
harte Kanten als auch glatte Verläufe der Tiefenwerte, welche sich in der Netzgeometrie durch 
adaptive Vernetzung mit reduziertem Datenaufwand darstellen lassen.

Dem Szenario der Web-basierten Remote-Visualisierung folgend soll der Web-Browser als
Klient-Komponente eingesetzt werden. Die einzusetzenden Technologien sind HTML5, Javascript, 
WebGL und WebSockets. Entsprechende Javascript-Bibliotheken sollen genutzt 
werden um die Qualität und Wartbarkeit des Quellcodes zu steigern. Für die Server-Komponente darf die Technologie vom Bearbeiter frei gewählt werden.

Zu Beginn der Arbeit wird eine Literatur-Recherche zu Web-basierter Visualisierung und Remote-Visualisierung erfolgen. 
Schwerpunkte  sind hierbei  die  Bild-Extrapolation, Vernetzung 
und Rekonstruktion auf Basis von Tiefenbildern und die Netzoptimierung und -Vereinfachung. 
Im Anschluss an die Literaturrecherche wird ein Konzept für die Implementierung mit dem 
Betreuer abgesprochen und anschließend als prototypische Software umgesetzt. Folgendes 
Szenario dient als Grundlage für dieses Konzept:

Als  Eingabedaten  stehen  mehrere  Datensätze aus  unterschiedlichen  Szenarien  der  wissenschaftlichen Visualisierung zur Verfügung. Für jeden Datensatz sind mehrere Tripel aus Farbbild, Tiefenbild und Kamera-Parameter gegeben.
Die Serverkomponente bereitet einen Datensatz auf und bietet ihn dem Klienten an. Diese Aufbereitung ist vor allem die Generierung einer optimierten  Tiefennetzgeometrie  aus  den  Tiefenbilddaten.  Der  Klient  fordert  Farbbilder,  Kameraeinstellungen und Tiefengeometrie von Tripel-Paaren an.
Konzeptuell wird ein Tripel als aktueller Zustand und das zweite Tripel als Ground-Truth einer Bildextrapolation verstanden. 
Diese können daher auch in dieser Reihenfolge angefordert werden. 
Die Tripel werden zwischen  Klient  und  Server  direkt  per  Sockets/WebSockets  übertragen.
Die Daten des ersten Tripels werden anschließend genutzt um dessen Farbbild in die Ansicht des zweiten Tripels extrapoliert. Hierbei werden vom zweiten Tripel nur die Kameraeinstellung genutzt.
Diese Extrapolation wird  Klient-seitig in WebGL implementiert  damit  alle  Berechnungen  auf  der  GPU 
ausgeführt werden. 
Anschließend wird das extrapolierte Bild mit dem originalen Ground-Truth-Farbbild  aus  dem  zweiten  Tripel  verglichen  um  die  Qualität  der  Extrapolation  zu  bewerten, z.B. durch SSIM.

Die umgesetzte Lösung wird ausführlich evaluiert.
Zentraler Wert ist hierbei die Bildqualität nach der Extrapolation abhängig vom Winkelunterschied zwischen den Kameraeinstellungen und den Parametern der Vereinfachung der Tiefennetzgeometrie. 
Hierfür werden Tripel-Paare aus den Datensätzen und Variationen der Parameter der Algorithmen systematisch 
und automatisiert vermessen. Untersuchungen zum Laufzeitverhalten der Netzoptimierung im Server 
und der Bildextrapolation im Klienten sind optional durchzuführen.
}

\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}

\acknowledgments{An dieser Stelle möchte ich meinen Eltern und meinen Freunden für ihre Unterstützung bedanken.}

\abstracten{abstract text english}
\abstractde{ Zusammenfassung Text Deutsch}

\usepackage[dvipsnames]{xcolor}
\usepackage{listings}
\usepackage{pgfplots}
\usepackage{filecontents}
\usepackage{subfigure}
\usepackage{float}
\usepackage{cancel}
\lstset{aboveskip=20pt,belowskip=20pt,belowcaptionskip=20pt,abovecaptionskip=20pt}
\tikzset{>=latex}

\setcounter{tocdepth}{2}

\input{../results/7/512x512_Full/default/16bit/5Pass/G1.0/results.tex}
\input{../results/7/512x512_Full/default/16bit/5Pass/G0.9/results.tex}
\input{../results/7/512x512_Full/default/16bit/5Pass/G0.8/results.tex}
\input{../results/6/512x512_Full/default/16bit/5Pass/G1.0/results.tex}
\input{../results/6/512x512_Full/default/16bit/5Pass/G0.9/results.tex}
\input{../results/6/512x512_Full/default/16bit/5Pass/G0.8/results.tex}
\input{../results/7/512x512_Full/default/8bit/5Pass/G1.0/results.tex}
\input{../results/7/512x512_Full/default/8bit/5Pass/G0.9/results.tex}
\input{../results/7/512x512_Full/default/8bit/5Pass/G0.8/results.tex}
\input{../results/6/512x512_Full/default/8bit/5Pass/G1.0/results.tex}
\input{../results/6/512x512_Full/default/8bit/5Pass/G0.9/results.tex}
\input{../results/6/512x512_Full/default/8bit/5Pass/G0.8/results.tex}
\input{../results/7/512x512_Full/default/16bit/3Pass/G1.0/results.tex}
\input{../results/7/512x512_Full/default/16bit/3Pass/G0.9/results.tex}
\input{../results/7/512x512_Full/default/16bit/3Pass/G0.8/results.tex}
\input{../results/6/512x512_Full/default/16bit/3Pass/G1.0/results.tex}
\input{../results/6/512x512_Full/default/16bit/3Pass/G0.9/results.tex}
\input{../results/6/512x512_Full/default/16bit/3Pass/G0.8/results.tex}
\input{../results/7/512x512_Full/default/8bit/3Pass/G1.0/results.tex}
\input{../results/7/512x512_Full/default/8bit/3Pass/G0.9/results.tex}
\input{../results/7/512x512_Full/default/8bit/3Pass/G0.8/results.tex}
\input{../results/6/512x512_Full/default/8bit/3Pass/G1.0/results.tex}
\input{../results/6/512x512_Full/default/8bit/3Pass/G0.9/results.tex}
\input{../results/6/512x512_Full/default/8bit/3Pass/G0.8/results.tex}

\input{../results/6/512x512_Delaunay/D10/L1.0/I1.0/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.1/I0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.0/I0.0/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.1/I0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.1/I0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.1/I0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.1/I0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.1/I0.1/_pre/results.tex}

\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}

\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}

\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.6/I0.4/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A0.1/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A0.1/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A1.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A1.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.9/I0.7/A10.0/J0.2/_pre/results.tex}

\input{../results/7/512x512_Delaunay/D10/L0.7/I0.6/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.7/I0.6/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.7/I0.6/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/7/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}

\input{../results/6/512x512_Delaunay/D10/L0.7/I0.6/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.7/I0.6/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.7/I0.6/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D10/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D9/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.1/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.2/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.3/_pre/results.tex}
\input{../results/6/512x512_Delaunay/D8/L0.7/I0.6/A10.0/J0.4/_pre/results.tex}


\input{../results/6/512x512_Delaunay/T1.0/G1.0/results.tex}
\input{../results/6/512x512_Delaunay/T0.9/G0.9/results.tex}
\input{../results/6/512x512_Delaunay/T0.8/G0.8/results.tex}
\input{../results/6/512x512_Delaunay/T0.7/G0.7/results.tex}
\input{../results/6/512x512_Delaunay/T0.6/G0.6/results.tex}
\input{../results/6/512x512_Delaunay/T0.5/G0.5/results.tex}
\input{../results/6/512x512_Delaunay/T0.4/G0.4/results.tex}
\input{../results/6/512x512_Delaunay/T0.3/G0.3/results.tex}
\input{../results/6/512x512_Delaunay/T0.2/G0.2/results.tex}
\input{../results/6/512x512_Delaunay/T0.1/G0.1/results.tex}
\input{../results/6/512x512_Delaunay/T0.0/G0.0/results.tex}

\input{../results/7/512x512_Delaunay/T1.0/G1.0/results.tex}
\input{../results/7/512x512_Delaunay/T0.9/G0.9/results.tex}
\input{../results/7/512x512_Delaunay/T0.8/G0.8/results.tex}
\input{../results/7/512x512_Delaunay/T0.7/G0.7/results.tex}
\input{../results/7/512x512_Delaunay/T0.6/G0.6/results.tex}
\input{../results/7/512x512_Delaunay/T0.5/G0.5/results.tex}
\input{../results/7/512x512_Delaunay/T0.4/G0.4/results.tex}
\input{../results/7/512x512_Delaunay/T0.3/G0.3/results.tex}
\input{../results/7/512x512_Delaunay/T0.2/G0.2/results.tex}
\input{../results/7/512x512_Delaunay/T0.1/G0.1/results.tex}
\input{../results/7/512x512_Delaunay/T0.0/G0.0/results.tex}

\input{../results/s_6_D10.tex}
\input{../results/s_6_D9.tex}
\input{../results/s_6_D8.tex}
\input{../results/s_7_D10.tex}
\input{../results/s_7_D9.tex}
\input{../results/s_7_D8.tex}
\input{../results/s_6floydSteinberg.tex}
\input{../results/s_7floydSteinberg.tex}

\input{../results/s_6_D10_cost.tex}
\input{../results/s_6_D9_cost.tex}
\input{../results/s_6_D8_cost.tex}
\input{../results/s_7_D10_cost.tex}
\input{../results/s_7_D9_cost.tex}
\input{../results/s_7_D8_cost.tex}
\input{../results/s_6floydSteinberg_cost.tex}
\input{../results/s_7floydSteinberg_cost.tex}

\input{../results/s_6_D10_triangle.tex}
\input{../results/s_6_D9_triangle.tex}
\input{../results/s_6_D8_triangle.tex}
\input{../results/s_7_D10_triangle.tex}
\input{../results/s_7_D9_triangle.tex}
\input{../results/s_7_D8_triangle.tex}
\input{../results/s_6floydSteinberg_triangle.tex}
\input{../results/s_7floydSteinberg_triangle.tex}

\input{../results/s_6_D8_L0.7_I0.6.tex}
\input{../results/s_6_D8_L0.7_I0.6_cost.tex}
\input{../results/s_6_D8_L0.7_I0.6_triangle.tex}
\input{../results/s_6_D9_L0.7_I0.6.tex}
\input{../results/s_6_D9_L0.7_I0.6_cost.tex}
\input{../results/s_6_D9_L0.7_I0.6_triangle.tex}
\input{../results/s_6_D10_L0.7_I0.6.tex}
\input{../results/s_6_D10_L0.7_I0.6_cost.tex}
\input{../results/s_6_D10_L0.7_I0.6_triangle.tex}

\input{../results/s_7_D8_L0.7_I0.6.tex}
\input{../results/s_7_D8_L0.7_I0.6_cost.tex}
\input{../results/s_7_D8_L0.7_I0.6_triangle.tex}
\input{../results/s_7_D9_L0.7_I0.6.tex}
\input{../results/s_7_D9_L0.7_I0.6_cost.tex}
\input{../results/s_7_D9_L0.7_I0.6_triangle.tex}
\input{../results/s_7_D10_L0.7_I0.6.tex}
\input{../results/s_7_D10_L0.7_I0.6_cost.tex}
\input{../results/s_7_D10_L0.7_I0.6_triangle.tex}


%\newcommand{}[ANZAHL][OPTIONAL]{DEFINITION}

\begin{document}

\chapter{Einleitung}

Bei der Remote-Visualisierung, wird die Bildsynthese und die eigentliche Darstellung voneinander getrennt.
Der Server-Prozess erzeugt und kodiert jedes Bild zu einem kompakten Datenpaket, 
welches an den Client-Prozess gesendet wird.
Der Client empfängt und dekodiert das Datenpaket und gibt das Bild auf einem Bildschirm aus.

Remote-Visualisierung ist ein insbesondere für mobile Endgeräte interessantes Konzept,
weil es die Visualisierung von komplexen Szenen auch auf leistungsarmen Geräten ermöglicht.
Neben Computerspielen, ist die wissenschaftliche Visualisierung ein wichtiges Anwendungsgebiet,
da Datensätze Größenordnungen erreichen können, 
die den Speicher herkömmlicher Desktops, Laptops, Smartphones etc. bei Weitem übersteigen. 
Auch wenn ausreichend Speicher zur Verfügung steht, 
kann die Übertragung dieser Daten viel Zeit in Anspruch nehmen.

Mit Hilfe der Remote-Visualisierung ist es möglich, dass der Server die Bildsynthese
übernimmt und nicht der komplette Datensatz übertragen werden muss.
Ein weiterer Vorteil der mit leistungsstarken Serversystemen einhergeht, ist der, 
dass sich komplexe Visualisierungs- und Beleuchtungsmethoden verwenden lassen, die mit normalen Endgeräten nicht zu realisieren sind.

Die Latenz bezeichnet in der Netzwerktechnik die Übertragungszeit von einem zum anderen Gerät.
Diese ist in modernen Netzwerken gering, für die interaktive Visualisierung allerdings immer
noch zu groß, um eine für den Menschen nicht wahrnehmbare Verzögerungszeit und 
damit eine interaktive Visualisierung zu gewährleisten.
Ein möglicher Ausweg besteht darin, dass der Client-Prozess ein bereits empfangenes Bild extrapoliert.
Das bedeutet, dass das noch nicht empfangene Bild aus den vorhanden Informationen approximiert
wird, wodurch die Bildwiederholfrequenz akzeptabel bleibt.

Bei der Bildsynthese des Server-Prozesses lässt sich, aus dem Tiefenpuffer ein Tiefenbild erzeugen, zusätzlich zum Farbbild.
Geometrisch entspricht das Tiefenbild einer 2.5D Ansicht der Szene.
Wird es zum Client gesendet, kann dieser das Tiefenbild als Punktwolke interpretieren.
Das approximierte Bild entsteht, indem die Punktwolke aus einer neuen Kameraperspektive gezeichnet wird.
Mit zunehmendem Winkelunterschied, zwischen der alten und der neuen Kameraperspektive,
werden die Lücken zwischen den Punkten, der Punktwolke, immer größer.
Durch die Erzeugung eines Dreiecksnetzes, aus dem Tiefenbild, lassen sich die Lücken
schließen.
Das Farbbild wird dabei als Textur über das Netz gelegt.

\begin{figure}[H]
	\subfigure[]{\includegraphics[width=.49\textwidth]{../Scenes/TestSpheres/run_1/testspheres_00000.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Full/default/16bit/5Pass/G1.0/frame_00277.png}}
\caption{Die Abbildungen zeigen die Extrapolation des ersten Bildes a, aus dem Datensatz \textit{TestSpheres}. Der Winkelunterschied zum Bild b beträgt 8 Grad.}
\label{fig:firstframes}
\end{figure}

Die Zentrale Aufgabe dieser Arbeit, ist die Optimierung und die Übertragung der 
Tiefeninformationen, vom Server zum Client.
Zu diesem Zweck erzeugt der Server, aus dem Tiefenbild ein adaptives Dreiecksnetz.
Dieses wird an den Client übertragen und extrapoliert. 
Mit Ground-Truth Datensätzen werden, in Abhängigkeit des Kamerawinkels, verschiedene
Ansätze hinsichtlich ihrer Güte evaluiert. 
Um die Algorithmen zu testen, wurde eine Server- und eine Client-Komponente entwickelt.
Beide Komponenten tauschen Informationen über das auf TCP basierende Websocket-Protokoll aus.
Der Client ist ein Browser-basierter Web-Client, damit die implementierten Algorithmen
mit den Einschränkungen durch JavaScript und WebGl evaluiert werden können.

Im Folgenden werden Arbeiten vorgestellt, 
die sich mit dieser Thematik bereits auseinander gesetzt haben.
Anschließend werden die Grundlagen dieser Arbeit erläutert.
In diesen Zusammenhang, werden die Datensätze vorgestellt.
Es wird gezeigt wie die Rückprojektion durchgeführt wird und 
wie die Gütemetriken funktionieren.
Danach werden die Algorithmen konzeptionell vorgestellt, gefolgt von Implementierungsdetails.
Als Nächstes folgt die Präsentation der Ergebnisse, die im darauf folgenden Kapitel ausgewertet werden.
Zum Schluss wird die gesamte Arbeit zusammengefasst und ein Ausblick
gegeben, wie die Ergebnisse weiter verbessert werden könnten.

\chapter{Verwandte Arbeiten}

Einen Überblick über Architekturen und Methoden der interaktiven Remote-Visualisierung geben Shu Shi \textit{et al.} \cite{Shi:2015:SIR:2775083.2719921}.
Zum zentralen Problem ihrer Arbeit wird die Latenz und die effiziente Übertragung der Daten vom Server zum Client.
Lösungen hängen vom Anwendungsfall ab.
Sie definieren \textit{THIN}-Systeme als eine Klasse von Remote-Visualisierungssystemen,
die auf die Übertragung von 2D Informationen beschränkt sind und die Bildwiederholfrequenz weitaus geringer sein kann, als es in interaktiven 3D-Anwendungen erforderlich ist. 
Das Ziel von \textit{THIN}-Systemen besteht darin Desktop-Anwendungen fernsteuern zu können.
Beispiele für existierende Architekturen sind \textit{SLIM} \cite{Schmidt:1999:IPS:319344.319154} und \textit{THiNC} \cite{Baratto:2005:TVD:1095809.1095837}. 
Sie sind für die Übertragung von 2D-Daten optimiert und profitieren davon, dass die meisten Änderungen nur Teilbereiche der eigentlichen Oberfläche betreffen.
Ein anderes Extrem der Remote-Visualisierung ist die Aufteilung der Bildsynthese
auf verschiedene Host-Systeme wie bei dem Cluster-basierten System WireGL \cite{Humphreys:2001:WSG:383259.383272}.
Jin Zhefan stellt in diesem Kontext Kompressionsmethoden für Zeicheninstruktionen, Vektoren, Normalen und Texturinformationen vor \cite{Jin:2006:RRI:1128923.1128927}.
Peter Eisert und Philipp Fechteler haben ein Remote-Visualisierungssystem für Computerspiele entwickelt \cite{Eisert07remoterendering}.
Ihr System überträgt bei kleinen Auflösungen für Endgeräte ohne GPU die Bilder
kodiert mit H.264 oder wahlweise MPEG-4.
Bei größeren Auflösungen werden Zeicheninstruktionen gesendet, und die Bilder werden
vom Client synthetisiert.
Auch wenn ihr System ausschließlich für den Einsatz in lokalen Netzwerken konzipiert wurde,
ist die Latenz zu hoch, um vom Benutzer nicht registriert zu werden.
Mit Hilfe einer Bildextrapolation durch den Client kann die Latenz reduziert werden. 
Zu diesen Zweck schätzen Shu \textit{et al.} in ihrer Arbeit \cite{1331221} 
zusätzliche Referenz-Kamerapositionen und erzeugen zusätzlich zum Farbbild der originalen
Kameraposition weitere Tiefenbilder.
Durch Warping werden die Farbinformationen unter Zuhilfenahme der Tiefenbilder
in die neue Kameraperspektive überführt. 
Dabei lassen sich durch Verdeckung bedingte Lücken, durch Pixel aus den Referenztiefenbilder schließen.
Das Farbbild wird mit JPEG komprimiert und die Tiefenbilder mit ZLIB.
Ein ähnlicher Ansatz wurde im VR-Bereich von Smit \textit{et al.} erprobt \cite{4810995}.
Auch in diesem System werden Lücken mit Hilfe von Tiefenbildern aus Referenz-Kamerapositionen
geschlossen.
Palomo \textit{et al.} nutzen ebenfalls einen Warping-Algorithmus, um mehrere Tiefenbilder und ein Farbbild miteinander zu vereinen. 
Zu diesem Zweck konstruieren sie mit Hilfe des Alpha-Farbkanals der
Bilder einen speziellen z-Buffer \cite{Palomo:2010:EAD:1900179.1900236},
um ihren Algorithmus komplett auf die GPU auslagern zu können.
Die Wahl des Warping-Algorithmus ist entscheidend für die Performance der Client-Komponente.
Neben der im VR-System zum Einsatz kommenden Variante \cite{Mark:1997:PW:253284.253292}
bieten Mark \textit{et al.} eine Übersicht über verschiedene Warping-Verfahren \cite{Mark99post-rendering3d}.
Die Erzeugung von mehreren Referenztiefenbildern ist eine rechenintensive Operation,
da von diesen nur wenige Pixel tatsächlich benötigt werden, um die verdeckungsbedingten Lücken
zu füllen.
Popescu und Aliaga haben zu diesen Zweck ein spezielles Kameramodell entworfen, dass verdeckte
Bildbereiche mit Hilfe gekrümmter Sichtstrahlen mitberechnen kann \cite{Popescu:2006:DDO:1111411.1111436}.
Die bisher vorgestellten Ansätze werden in dieser Arbeit nicht aufgegriffen; sie sollen
verdeutlichen, welche alternativen Möglichkeiten existieren.
  
Die effiziente Übertragung und Visualisierung von Tiefenbildern
ist auch für die Arbeit mit Tiefensensorsystemen von großem Interesse.
Banno \textit{et al.} erzeugen aus Tiefenbildern, die durch Tiefensensoren erhoben wurden,
Dreicksnetze mit Hilfe der Delaunay-Triangulierung \cite{Banno:2012:RCD:2407516.2407579}.
Ausgangspunkt für die Vernetzung ist eine Menge von Punkten, die Kanten und Krümmungen
im Tiefenbild repräsentieren.
Zur Erzeugung dieser Punkte kommt ein Quadtree zum Einsatz.
Zusätzlich haben sie ein Verfahren entwickelt, um das erzeugte Netz in einem weiteren Schritt,
hinsichtlich der optischen Qualität, zu verbessern.
Einen alternativen Ansatz für die Erzeugung der zur Vernetzung benötigten Punktmenge
wird von Lee \textit{et al.} vorgestellt \cite{900943}.
Sie nutzen ein Fehlerdiffusionsverfahren, um in der Nähe von Kanten Punkte zu platzieren.
In beiden Arbeiten wird die Extrapolation der Bilder durch die Rückprojektion der Dreiecksnetze durchgeführt.
Diese beiden Ansätze bilden den Kern dieser Arbeit.

Um die Latenz bei der Übertragung zu verbessern, können mehrere Qualitätsstufen von einem Dreiecksnetz
erzeugt werden, wie in der Arbeit von Chai \textit{et al.} \cite{1024050},
die auf dem Verfahren von Lindstrom \textit{et al.} basiert \cite{Lindstrom:1996:RCL:237170.237217}.
Mwalongo \textit{et al.} haben einen hybriden Ansatz entwickelt, der zusätzlich
zu einzelnen Vertices des Netzes Parameter für Kugeln übermittelt, die anschließend vom
Client rekonstruiert werden \cite{Mwalongo:2015:RVD:2775292.2775307}.
Evans \textit{et al.} haben ein Dateiformat für Punktwolken entwickelt, um diese progressiv
an einen auf WebGL basierten Client zu senden \cite{Evans:2014:WVO:2668904.2668937}. 


Wessels \textit{et al.} stellen eine Konzeption für den Programmaufbau eines interaktiven Remote-Visualisierungssystem basierend auf dem WebSocket-Protokoll vor \cite{DBLP:conf/itng/WesselsPJR11}.
In ihrem System besteht der Server-Prozess aus zwei Hauptkomponenten,
der Visualisierungs-Engine und dem Deamon. 
Während die Visualisierungs-Engine für die Bildsynthese zuständig ist, 
übernimmt der Deamon die Kommunikation mit dem Client-Prozess.
Der Client schickt dabei seine Eingabeinformationen von Maus und Tastatur direkt an den Server.
Dieser wertet die Daten aus und erzeugt daraufhin ein mit JPEG komprimiertes Bild, das mit Base64 kodiert wird und schließlich an den Client-Prozess geschickt wird. 
Dieser kann das Bild nativ mit Hilfe eines HTML5 Canvas dekodieren und darstellen.
Ihr System wird zur Grundlage für die in dieser Arbeit verwendete Softwarearchitektur.

Auch wenn die Kompression und kompakte Kodierung der Dreiecksnetze nicht Teil dieser Arbeit sind,
sollen die folgenden Arbeiten einen Überblick über mögliche Techniken geben.
Gabriel Taubin und Jarek Rossignac haben ein Algorithmus zur Erzeugung und effizienten Kodierung von Dreiecksstreifen aus Dreiecksnetzen entwickelt \cite{Taubin:1998:GCT:274363.274365}.
Dazu konstruiert ihr Algorithmus Spannbäume über dem Netz, die zur Erzeugung möglichst großer
Dreiecksstreifen genutzt werden. 
Die Kompression kann wahlweise verlustfrei oder verlustbehaftet
durchgeführt werden. 
Typische Kompressionsraten werden mit 1:50 angegeben.
Eine weitere Arbeit, die sich mit der Kompression von Dreiecksnetzen und einer kompakten Repräsentation
von diesen beschäftigt, wurde Stefan Gumhold und Wolfgang Straßer geschrieben \cite{Gumhold:1998:RTC:280814.280836}.
Kompression und Dekompression sind echtzeitfähig.
Weitere geometrische Kompressionsverfahren für Vertices, Indices und Normalen, sind in der Arbeit von
Michael Deering zu finden \cite{Deering:1995:GC:218380.218391}.
Sowie in der Arbeit \cite{gotsman-touma-gi98} von den Autoren Touma und Gotsman.

\chapter{Grundlagen}

In diesem Kapitel werden die Datensätze im Detail vorgestellt und es wird gezeigt,
wie die Bildextrapolation anhand der zur Verfügung stehenden Informationen 
durchgeführt wird.
Anschließend werden die zwei Metriken PSNR und SSIM zum Vergleich von Bildern vorgestellt,
die für die Evaluation verwendet werden.

\section{Datensätze}

Zur Analyse der verwendeten Methoden stehen zwei Datensätze zur Verfügung.
Jeder Datensatz besteht aus einer Sequenz von Tripeln.
Dabei setzt sich jedes Tripel aus einem Farbbild, einem Tiefenbild $D$ 
sowie einem Satz von Kameraparametern zusammen.
Die Auflösung der Farb- und Tiefenbilder beträgt für alle Datensätze $w \times h = 512 \times 512$.
Die Tiefenbilder wurden mit 16 Bit und die Farbbilder mit 24 Bit quantisiert, dabei entfallen jeweils
8 Bit auf die einzelnen Farbkanäle.
In der Abbildung \ref{fig:testspheres_40_id} werden Farb- und Tiefenbild des ersten Frames aus den beiden Datensätzen,
\textit{TestSpheres} und \textit{CoolRandom} dargestellt.

\begin{figure}[h]
	\centering
	\subfigure[\textit{TestSpheres}]{\includegraphics[width=.4\textwidth]{../Scenes/TestSpheres/run_2/testspheres_00000.png}}
	\subfigure[\textit{CoolRandom}]{\includegraphics[width=.4\textwidth]{../Scenes/CoolRandom/run_2/coolrandom_00000.png}}
	
	\subfigure[\textit{TestSpheres}]{\includegraphics[width=.4\textwidth]{../Scenes/TestSpheres/run_2/testspheres_00000_depth.png}}
	\subfigure[\textit{CoolRandom}]{\includegraphics[width=.4\textwidth]{../Scenes/CoolRandom/run_2/coolrandom_00000_depth.png}}
	\caption{Farb- und Tiefenbilder der ersten Frames, von beiden Datensätzen.}
	\label{fig:testspheres_40_id}
\end{figure}

Die Kameraparameter setzen sich aus einem Vektor für die Kameraposition, einem \textit{lookAt}-Vektor, der Punkt, auf den die Kamera schaut und dem \textit{up}-Vektor zusammen.
Für die Projektion werden die Positionen der Clippingebenen durch die Werte $z_{near}$ und $z_{far}$ beschrieben.
Des Weiteren wird der Öffnungswinkel der Kamera benötigt.

Von beiden Szenen stehen 493 Bilder zur Verfügung.
Beide Datensätze lassen sich in Abhängigkeit der Winkelschrittweite in 3 Sequenzen unterteilen.
Der Winkel gibt dabei den Unterschied zwischen der Kameraposition aus dem ersten und dem gerade betrachteten Frame an.
Eine Auflistung der Sequenzen zeigt die Tabelle \ref{tab:datasets}.

\begin{table}[h]
	\begin{tabular}{c|c|c|c|c}
		\# & Anzahl Bilder & min Winkel &  max Winkel & Winkel Schritt \\
		\hline
		1 & 241 & 0  & 5  & 0.25 \\
		2 & 60  & 6  & 10 & 1 	 \\
		3 & 192 & 15 & 90 & 5  	 \\
	\end{tabular}
	\centering
	\caption{Die Tabelle zeigt eine Übersicht über die Winkel der aufgenommenen Sequenzen.}
	\label{tab:datasets}
\end{table}

Die Datensätze \textit{CoolRandom} und \textit{TestSpheres} wurden aus Partikeldatensätzen erzeugt.
\textit{TestSpheres} ist ein synthetisch erzeugter Datensatz, der aus wenigen Partikeln generiert wurde.
Bei dem Datensatz \textit{CoolRandom} handelt es sich dagegen um einen komplexen Datensatz,
der mit Molekül-Datensätzen vergleichbar ist, welche in existierenden Anwendungen visualisiert werden.

Weiterhin zu beachten ist, dass das Tiefenbild des ersten Frames, aus dem \textit{TestSpheres}-Datensatz ein Fehler aufweist.
Die vorderste Kugel, in der Abbildung \ref{fig:testspheres_40_id}, als die dunkelste Kugel zu sehen ist im Tiefenbild 
nicht vollständig repräsentiert. Sie weist nur an den Seiten Krümmungen auf, ist im inneren jedoch vollkommen flach.

\section{Extrapolation}

Eine einfache Möglichkeit, um die Extrapolation durchzuführen, besteht darin, das Tiefenbild als Punktwolke
zu interpretieren und diese aus einer neuen Kameraperspektive zu zeichnen.
Dazu wird aus jedem Pixel $d \in D$ ein Vertex erzeugt. 
Mit Hilfe der Rückprojektion lassen sich die Vertices in die gewünschten Positionen transformieren.

Um das Prinzip der Rücktransformation zu erläutern, soll zunächst betrachtet werden, wie ein Vertex $v$
aus dem Modellkoordinatensystem in normalisierte Gerätekoordinaten transformiert wird.
Die Abbildung \ref{fig:Transformation} verdeutlicht diesen Vorgang. 

\begin{figure}[h]
	\begin{tikzpicture}
		\begin{scope}[auto, every node/.style={minimum size=7em, align=center}]
			\node[draw] (A) at (0,0) {Modell-\\koordinaten};
			\node[draw] (B) at (4,0) {Welt-\\koordinaten};
			\node[draw] (C) at (8,0) {Kamera-\\koordinaten};
			\node[draw] (D) at (12,0) {normalisierte \\Geräte- \\koordinaten};
		\end{scope}
		\draw[->, gray, line width=1mm] (A) -- (B);
		\draw[->, gray, line width=1mm] (B) -- (C);
		\draw[->, gray, line width=1mm] (C) -- (D);
	\end{tikzpicture}
	\centering
	\caption{Die Abbildung zeigt die Teilschritte der Transformation eines Vertices aus den Modellkoordinaten in Bildschirmkoordinaten.}
	\label{fig:Transformation}
\end{figure}

Der Vertex $v = (x, y, z, 1)^T$ liegt zunächst in homogenen Modellkoordinaten vor.
Mit Hilfe der Modellmatrix $M = RT$, die aus einer Rotations- und einer Translationsmatrix besteht, 
lässt sich der Vektor in das Weltkoordinatensystem überführen.
Die Transformation in das Kamerakoordinatensystem wird durch die Multiplikation der Kameramatrix $V$ mit dem Vertex $v$ berechnet.
Schließlich kann die Projektion aus dem Kamerakoordinatensystem in normalisierte Gerätekoordinaten mit Hilfe
der Projektionsmatrix $P$ berechnet werden.
In der Gleichung \ref{eq:ModelViewProjektion} wird die Transformation von dem Vertex $v$ aus
den Modellkoordinaten in die normalisierten Gerätekoordinaten $v'$ zusammengefasst:

\begin{equation}
	v' = M \cdot V \cdot P \cdot v.
	\label{eq:ModelViewProjektion}
\end{equation}

Normalisierte Gerätekoordinaten haben für die x-,y- und z-Komponente den Wertebereich von
$-1$ bis $1$. 
Diese lassen sich in Bildschirmkoordinaten umrechnen, indem die drei Komponenten in das
Intervall $[0, 1]$ übersetzt werden.
Anschließend werden die x- und die y-Komponenten
auf den Bildbereich gestreckt, indem sie mit $w-1$ und $h-1$ der gewünschten Auflösung
$w \times h$ multipliziert werden. 

Im Folgenden wird die Menge der Tiefenbilder $D_i$ und den dazugehörigen Transformationsmatrizen $T_i$, mit $i \in \{0,1, ..., N \}$ betrachtet.
Jede Transformatiosmatrix $T_i$ setzt sich dabei aus einer Modellmatrix $M_i$, einer Kameramatrix $V_i$ und einer
Projektionsmatrix $P_i$ zusammen:

\begin{equation}
	T_i = M_i \cdot V_i \cdot P_i.
\end{equation}

Um die Punktwolke des Tiefenbildes $D_i$ mit der Transformationsmatrix $T_j$ auf das Tiefenbild $D_j$
abzubilden, muss zunächst für jeden Pixel $d_i \in D_i$ ein Vertex $v_i$ erzeugt werden, mit $i,j \in \{0,1, ..., N \}$.
Zunächst liegt $v_i$ in Bildschirmkoordinaten des Pixels $d_i$ vor und muss in normalisierte Gerätekoordinaten übersetzt werden. 
Zu diesem Zweck werden zuerst die x- und y-Kompontenten durch $w-1$ beziehungsweise $h-1$ geteilt.
Anschließend müssen alle drei Komponenten des Vektors $v_i$ aus dem Werteintervall $[0, 1]$
in das Intervall $[-1, 1]$ transformiert werden.
Jetzt liegt $v_i$ in normalisierten Gerätekoordinaten vor.
Durch die Multiplikation der inversen Transformationsmatrix $T_i^{-1}$ mit $v_i$, 
kann der Vertex in seine Modellkoordinaten überführt und
im Anschluss mit Hilfe von $T_j$
aus einer neuen Kameraperspektive gezeichnet werden:

\begin{equation}
	v_i' = T_j \cdot T_i^{-1} v_i.
\end{equation}

Die Interpretation der Tiefenbilder als Punktwolke ist keine optimale Lösung,
da bei der Bildsynthese Lücken im Bild entstehen.
Eine leistungsfähigere Lösung ist es, aus dem Tiefenbild ein Dreiecksnetz zu erzeugen
und dieses für die Bildsynthese zu verwenden.
Mit Hilfe der Delaunay-Triangulierung ist es möglich, aus Tiefenbildern
adaptive Dreiecksnetze zu erzeugen, welche die Lücken füllen.

\begin{figure}[H]
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/CoolRandom_PointCloud_199}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/TestSpheres_PointCloud_306.png}}
\end{figure}

\section{Delaunay-Triangulierung}

Die Delaunay-Triangulierung ist ein Verfahren, um ein Dreiecknetz aus einer Menge von
Punkten $p \in \mathbb{R}^{2}$ zu erzeugen.
Dabei wird für jedes Dreieck ein Umkreis erzeugt, innerhalb dessen keine Punkte eines anderen
Dreiecks enthalten sein dürfen.
Jedes Dreieck des zu erzeugenden Netzes muss diese Bedingung erfüllen.
Das Resultat dieser Forderung ist die maximierte Innenwinkelsumme aller Dreiecke.
Für eine gegebene Punktmenge ist die Lösung nicht eindeutig, es kann verschiedene
Netzkonfigurationen geben, welche die Forderung erfüllen.

Es existieren verschiedene Algorithmen die Delaunay-Triangulierung durchzuführen.
Die schnellsten erreichen eine Laufzeit von $O(n \log n)$ und sind damit
für den Einsatz in Echtzeitanwendungen tauglich.
Beispiele hierfür sind der Sweep-Algorithmus und die inkrementelle Konstruktion.

\section{Bildvergleich}

Im Folgenden werden zwei Metriken zum Vergleich von Bildern vorgestellt.
Sie werden genutzt, um die Ähnlichkeit zwischen den extrapolierten
und den Ground-Truth Bildern zu bestimmen.
Beide Metriken werden für jeden Farbkanal separat berechnet. 

\subsection{PSNR}

Die Abkürzung PSNR, im Englischen \textit{Peak signal-to-noise ratio}, 
gibt das Verhältnis zwischen dem Maximalwert des Signals, auch als Nutzleistung bezeichnet, und dem Einfluss des Rauschens, also der Störleistung, an. 
Der PSNR wird auf eine logarithmische Skala abgebildet,
weil die Nutzleistung in der Regel wesentlich größer als die Störleistung ist.

Um die Stärke des Fehlers zu bestimmen, wird der \textit{mean squared error}, kurz $MSE$ verwendet. 
Dieser lässt sich bestimmen, indem innerhalb eines Fensters der Größe $m \times n$
die quadratischen Abstände zwischen dem Originalbild $I$ und dem 
rekonstruierten Bild $K$ aufsummiert werden:

\begin{equation}
	MSE = \frac{1}{mn} \sum\limits_{i=0}^{m-1} \sum\limits_{j=0}^{n-1}[I(i, j) - K(i, j)]^2.
\end{equation}

Der PSNR ist der Quotient, gebildet aus dem maximal möglichen Farbwert $MAX_I$,
des untersuchten Farbkanals und dem $MSE$:

\begin{align}
PSNR &= 10 \times \log_{10} \left( \frac{MAX^2_I}{MSE} \right) \\
	 &= 20 \times \log_{10} \left( \frac{MAX_I}{\sqrt{MSE}} \right) \\
	 &= 20 \times \log_{10} (MAX_I) - 10 \times \log_{10} (MSE)
\end{align}

Bei einer Farbtiefe von 8 Bit pro Kanal, stehen Werte von 30 - 40 dB für ein
geringes Störsignal und gleichzeitig für eine höhere Übereinstimmung der Bilder.
Der PSNR ist ein häufig genutztes Maß, 
um die Ähnlichkeit zweier Bilder zu bestimmen.

\section{SSIM}

Im Gegensatz zum PSNR ist die von Wang \textit{et al.} entwickelte Metrik
\textit{structural similarity index} ein auf die menschliche Wahrnehmung angepasstes Modell\cite{Wang04imagequality}.
Die Metrik basiert auf der Idee auf, dass die Struktur der abgebildeten Objekte
unabhängig von Beleuchtung und Kontrast gemessen werden kann.

Die mittlere Intensität des diskreten Signals $x$ lässt sich in
einem lokalen Bereich der größe $N$ folgendermaßen bestimmen:

\begin{equation}
	\mu_x = \frac{1}{N} \sum\limits_{i=1}^{N} x_i.
\end{equation}

Die Vergleichsfunktion, welche die Beleuchtung zwischen zwei Signalen $x$ und $y$
misst, wird durch dem Term $l(x, y)$ repräsentiert.
Dieser setzt die mittleren Intensitäten $\mu_x$ und $\mu_y$ wie folgt ins Verhältnis:

\begin{equation}
	l(x, y) = \frac{2\mu_x \mu_y + C_1}{\mu^2_x + \mu^2_y + C_1}.
\end{equation}

Die Konstante $C_1$ wird benötigt, um die numerische Stabilität
zu gewährleisten.
Analog zur Abbildung \ref{fig:SSIM_DIAGRAM} wird im Anschluss an die Beleuchtungsmessung die mittlere Intensität von beiden Signalen $x - \mu_x$ und $y - \mu_y$ abgezogen.

Der Kontrast wird unter Verwendung der Standardabweichung $\sigma_{x}$ approximiert.
In diskreter Form lässt sich diese mit der folgenden Formel berechnen:

\begin{equation}
	\sigma_{x} = \left( \frac{1}{N-1} \sum\limits_{i=1}^{N} (x_i - \mu_{x})^{2} \right)^\frac{1}{2}.
\end{equation}

Die Vergleichsfunktion für den Kontrast wird mit $c(x, y)$ bezeichnet und definiert sich wie folgt:

\begin{equation}
	c(x, y) = \frac{2\sigma_x \sigma_y + C_2}{\sigma^2_x + \sigma^2_y + C_2}.
\end{equation}

Wie bei der Berechnung der mittleren Intensität wird eine Konstante $C_2$
eingeführt.
An dieser Stelle wird das Signal normalisiert, 
indem es durch seine eigene Standardabweichung geteilt wird und 
die beiden Signale $(x - \mu_{x}) / \sigma_x$, $(y - \mu_{y}) / \sigma_y$ entstehen.
Der Vergleich der strukturellen Eigenschaften $s(x, y)$ wird mit den normalisierten Signalen durchgeführt.
Für den Vergleich der Struktur sollen folgende Eigenschaften gelten:

\begin{figure}
	\begin{tikzpicture}[scale=0.7]
			\begin{scope}[auto, every node/.style={}]
				\node[] 										(A) at (0,0) 		{\small Signal $x$};
				\node[draw, circle] 							(B) at (5,-1.5) 	{\small $+$};
				\node[draw, circle] 							(C) at (10,-3) 		{\small $\div$};
				\node[draw, align=center, minimum width=2cm] 	(D) at (3,0) 		{\small Luminanz \\ -messung};
				\node[draw, align=center, minimum width=2cm] 	(E) at (7.5,-1.5) 	{\small Kontrast \\ -messung};
				\node[draw, align=center, minimum width=2cm] 	(F) at (13,-1.5) 	{\small Luminanz \\ -messung};
				\node[draw, align=center, minimum width=2cm] 	(G) at (13,-4) 		{\small Kontrast \\ -messung};
				\node[draw, align=center, minimum width=2cm] 	(H) at (13,-6.5) 	{\small Struktur \\ -messung};
				\node[draw, align=center, minimum height=1.3cm] (I) at (16.5,-4) 	{\small Kombination};
				\node[align=center] 							(J) at (20,-4) 		{\small Ähnlichkeits \\ -messung};
				\node[] 										(K) at (0,-5) 		{\small Signal $y$};
				\node[draw, circle] 							(L) at (5,-6.5) 	{\small $+$};
				\node[draw, circle] 							(M) at (10,-8) 		{\small $\div$};
				\node[draw, align=center, minimum width=2cm] 	(N) at (3,-5) 		{\small Luminanz \\ -messung};
				\node[draw, align=center, minimum width=2cm] 	(O) at (7.5,-6.5) 	{\small Kontrast \\ -messung};
			\end{scope}
			
			\draw[->, thick] (A) -- (D);
			\draw[->, thick] (D) -- (11, 0) -- (F.west);
			\draw[->, thick] (1.2, 0) |- (B) 	node[inner sep=8pt, anchor=north east] {+};
			\draw[->, thick] (5, 0) -- (B) 		node[inner sep=8pt, anchor=south west] {-};
			\draw[->, thick] (B) -- (E);
			\draw[->, thick] (E) -- (11, -1.5) -- (G.west);
			\draw[->, thick] (5.7, -1.5) |- (C);
			\draw[->, thick] (10, -1.5) -- (C);
			\draw[->, thick] (C) -- (11, -3) -- (H.west);
			\draw[->, thick] (K) -- (N);
			\draw[->, thick] (N) -- (11, -5) -- (F.west);
			\draw[->, thick] (1.2, -5) |- (L) 	node[inner sep=8pt, anchor=north east] {+};
			\draw[->, thick] (5, -5) -- (L) 	node[inner sep=8pt, anchor=south west] {-};
			\draw[->, thick] (L) -- (O);
			\draw[->, thick] (O) -- (11, -6.5) -- (G.west);
			\draw[->, thick] (5.7, -6.5) |- (M);
			\draw[->, thick] (10, -6.5) -- (M);
			\draw[->, thick] (M) -- (11, -8) -- (H.west);			
			\draw[->, thick] (G) -- (I);
			\draw[->, thick] (F) -| (I.north);
			\draw[->, thick] (H) -| (I.south);
			\draw[->, thick] (I) -- (J);
	\end{tikzpicture}
	\centering
	\caption{Das Modell zeigt das Vorgehen von dem SSIM-Algorithmus \cite{Wang04imagequality}.}
	\label{fig:SSIM_DIAGRAM}
\end{figure}

Erstens: Die Funktion $s(x, y)$ muss symmetrisch sein $s(x, y) = s(y, x)$.

Zweitens: Soll die Funktion auf einen Wert kleiner oder gleich $1$ beschränkt werden $s(x, y) \le 1$.

Drittens: Es soll nur ein Maximum $s(x, y) = 1$ geben, 
genau dann und nur dann, wenn gilt, dass $x = y$.

Die folgende Definition erfüllt alle drei Forderungen:

\begin{equation}
	s(x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x + \sigma_y + C_3}.
\end{equation}

Die Kovarianz $\sigma_{xy}$ berechnet sich folgendermaßen:

\begin{equation}
	\sigma_{xy} = \frac{1}{N-1} \sum\limits_{i=1}^{N} (x_i - \mu_x)(y_i - \mu_y).
\end{equation}

Sie korreliert mit dem Kosinus des Winkels zwischen den beiden Vektoren
$x - \mu_x$ und $y - \mu_y$.
Die Konstanten $C_1, C_2$ und $C_3$ in den drei Vergleichsfunktionen
sorgen dafür, dass eine Division durch 0 nicht möglich wird, sollten
die Werte in den Nennern zu klein werden.
Letztlich kann die Gesamtqualität gemessen werden, indem Beleuchtung,
Kontrast und Strukturvergleich kombiniert werden:

\begin{equation}
	SSIM(x, y) = [l(x,y)]^\alpha \times [c(x, y)]^\beta \times [s(x, y)]^\gamma.
\end{equation}

Mit den Parametern $\alpha > 0, \beta > 0, \gamma > 0$ kann die
Gewichtung zwischen den Vergleichsfunktionen variiert werden.
Im Rahmen dieser Arbeit gilt $\alpha = \beta = \gamma = 1$ und
es gilt für die Konstanten:
$C_3 = C_2 / 2$, mit $C_1 = 6.5025$ und $C_2 = 58.5225$.
Der $SSIM$ wird lokal, berechnet.
Dabei werden die Signalwerte $x_i$ und $y_i$ mit einer Gaussianfunktion
gewichtet.
Damit lassen sich die mittlere Intensität, die Standardabweichung
und die Kovarianz zu folgenden Gleichungen umformen, wobei $w_i$
die Gewichtung an dem Punkt $i$ bezeichnet:

\begin{align}
	\mu_x &= \sum\limits_{i=1}^{N} w_i x_i \\
	\sigma_x &= \left( \sum\limits_{i=1}^{N} w_i(x_i - \mu_x)^2 \right)^\frac{1}{2} \\
	\sigma_{xy} &= \sum\limits_{i=1}^{N} w_i(x_i - \mu_x)(y_i - \mu_y).
\end{align}

Damit lässt sich der $SSIM(x, y)$ durch die folgende Gleichung bestimmen:

\begin{equation}
	SSIM(x, y) = \frac{(2 \mu_x \mu_y + C_1)(2\sigma_{xy} + C_2)}{(\mu^2_x + \mu^2_y + C_1)(\sigma^2_x + \sigma^2_y + C_2)}.
\end{equation}

Der $SSIM(x, y)$ misst die Güte jedoch nur lokal.
Um eine Aussage über das gesamte Bild treffen zu können, wird der
Mittelwert über allen $x \in X$ und $y \in Y$ berechnet:

\begin{equation}
	MSSIM(X, Y) = \frac{1}{M} \sum\limits_{j=1}^{M} SSIM(x_j, y_j).
\end{equation}

Die Evaluation wird mit beiden Metriken durchgeführt um eine bessere Vergleichbarkeit
mit anderen Arbeiten zu gewährleisten.

\chapter{Methodik}

In dieser Arbeit werden zwei grundsätzliche Verfahren untersucht, um die Tiefeninformationen zu übertragen
und als Dreiecksnetz darzustellen.
Der erste Ansatz besteht darin, das Tiefenbild als solches verlustfrei zu komprimieren und zu übertragen.
Der Client empfängt und dekodiert das Tiefenbild und erzeugt daraus ein voll vernetztes Dreiecksnetz.
Im zweiten Ansatz wird aus dem Tiefenbild ein adaptives Dreiecksnetz mit Hilfe
der Delaunay-Triangulierung vom Server konstruiert und an den Client übertragen.

Die Erzeugung von adaptiven Dreiecksnetzen lässt sich als eine Form der 
verlustbehafteten geometrischen Kompression bezeichnen.
Die zu übertragende Informationsmenge lässt sich durch Valenz-basierte Kodierung weiter verringern.

Weil die Tiefenwerte des Tiefenbildes komplett und ohne Informationsverlust
im voll vernetzen Dreiecksnetz enthalten sind, liefert dieses Verfahren Ergebnisse,
die als \textit{Ground-Truth}-Information zum Vergleich der adaptiven Vernetzung dienen. 

\section{Vollvernetzung}

Bei der Vollvernetzung wird für jeden Pixel aus dem Tiefenbild $D$ ein Vertex erzeugt.
Die entstandenen Vertices werden über Kanten zu Dreiecken miteinander verbunden.
Die Abbildung \ref{fig:FULL_MESH} zeigt drei unterschiedliche Varianten, wie sich die
Vertices zu voll vernetzten Dreiecksnetzen verbinden lassen.
Alle drei Varianten wurden im Rahmen dieser Arbeit implementiert, weisen bei entsprechend großen Auflösungen
jedoch keine Unterschiede hinsichtlich der Qualität der Darstellung auf.

\begin{figure}[h]
	\subfigure[]{
	\begin{tikzpicture}[scale=0.5, every node/.style={scale=0.5}]
		\begin{scope}[
			auto, vertice/.style={align=center, draw, circle, minimum width=2em, inner sep=2pt}]
			\node[vertice] (V0) at (0,0) {$0$};
			\node[vertice] (V1) at (2,0) {$1$};
			\node[vertice] (V2) at (4,0) {$2$};
			\node[vertice] (V3) at (6,0) {$3$};
			\node[vertice] (V4) at (8,0) {$4$};
			
			\node[vertice] (V5) at (0,-2) {$5$};
			\node[vertice] (V6) at (2,-2) {$6$};
			\node[vertice] (V7) at (4,-2) {$7$};
			\node[vertice] (V8) at (6,-2) {$8$};
			\node[vertice] (V9) at (8,-2) {$9$};
			
			\node[vertice] (V10) at (0,-4) {$10$};
			\node[vertice] (V11) at (2,-4) {$11$};
			\node[vertice] (V12) at (4,-4) {$12$};
			\node[vertice] (V13) at (6,-4) {$13$};
			\node[vertice] (V14) at (8,-4) {$14$};

			\node[vertice] (V15) at (0,-6) {$15$};
			\node[vertice] (V16) at (2,-6) {$16$};
			\node[vertice] (V17) at (4,-6) {$17$};
			\node[vertice] (V18) at (6,-6) {$18$};
			\node[vertice] (V19) at (8,-6) {$19$};
			
			\node[vertice] (V20) at (0,-8) {$20$};
			\node[vertice] (V21) at (2,-8) {$21$};
			\node[vertice] (V22) at (4,-8) {$22$};
			\node[vertice] (V23) at (6,-8) {$23$};
			\node[vertice] (V24) at (8,-8) {$24$};		
		\end{scope}
		
		\draw[-] (V0) edge (V1); \draw[-] (V1) edge (V5); \draw[-] (V5) edge (V0);
		\draw[-] (V1) edge (V6); \draw[-] (V6) edge (V5); \draw[-] (V5) edge (V1);
		\draw[-] (V1) edge (V2); \draw[-] (V2) edge (V6); \draw[-] (V6) edge (V1);
		\draw[-] (V2) edge (V7); \draw[-] (V7) edge (V6); \draw[-] (V6) edge (V2);
		\draw[-] (V2) edge (V3); \draw[-] (V3) edge (V7); \draw[-] (V7) edge (V2);
		\draw[-] (V3) edge (V8); \draw[-] (V8) edge (V7); \draw[-] (V7) edge (V3);
		\draw[-] (V3) edge (V4); \draw[-] (V4) edge (V8); \draw[-] (V8) edge (V3);
		\draw[-] (V4) edge (V9); \draw[-] (V9) edge (V8); \draw[-] (V8) edge (V4);
		
		\draw[-] (V5) edge (V6);  \draw[-] (V6) edge (V10);  \draw[-] (V10) edge (V5);
		\draw[-] (V6) edge (V11); \draw[-] (V11) edge (V10); \draw[-] (V10) edge (V6);
		\draw[-] (V6) edge (V7);  \draw[-] (V7) edge (V11);  \draw[-] (V11) edge (V6);
		\draw[-] (V7) edge (V12); \draw[-] (V12) edge (V11); \draw[-] (V11) edge (V7);
		\draw[-] (V7) edge (V8);  \draw[-] (V8) edge (V12);  \draw[-] (V12) edge (V7);
		\draw[-] (V8) edge (V13); \draw[-] (V13) edge (V12); \draw[-] (V12) edge (V8);
		\draw[-] (V8) edge (V9);  \draw[-] (V9) edge (V13);  \draw[-] (V13) edge (V8);
		\draw[-] (V9) edge (V14); \draw[-] (V14) edge (V13); \draw[-] (V13) edge (V9);

		\draw[-] (V10) edge (V11); \draw[-] (V11) edge (V15); \draw[-] (V15) edge (V10);
		\draw[-] (V11) edge (V16); \draw[-] (V16) edge (V15); \draw[-] (V15) edge (V11);
		\draw[-] (V11) edge (V12); \draw[-] (V12) edge (V16); \draw[-] (V16) edge (V11);
		\draw[-] (V12) edge (V17); \draw[-] (V17) edge (V16); \draw[-] (V16) edge (V12);
		\draw[-] (V12) edge (V13); \draw[-] (V13) edge (V17); \draw[-] (V17) edge (V12);
		\draw[-] (V13) edge (V18); \draw[-] (V18) edge (V17); \draw[-] (V17) edge (V13);
		\draw[-] (V13) edge (V14); \draw[-] (V14) edge (V18); \draw[-] (V18) edge (V13);
		\draw[-] (V14) edge (V19); \draw[-] (V19) edge (V18); \draw[-] (V18) edge (V14);
		
		\draw[-] (V15) edge (V16); \draw[-] (V16) edge (V20); \draw[-] (V20) edge (V15);
		\draw[-] (V16) edge (V21); \draw[-] (V21) edge (V20); \draw[-] (V20) edge (V15);
		\draw[-] (V16) edge (V17); \draw[-] (V17) edge (V21); \draw[-] (V21) edge (V16);
		\draw[-] (V17) edge (V22); \draw[-] (V22) edge (V21); \draw[-] (V21) edge (V17);
		\draw[-] (V17) edge (V18); \draw[-] (V18) edge (V22); \draw[-] (V22) edge (V17);
		\draw[-] (V18) edge (V23); \draw[-] (V23) edge (V22); \draw[-] (V22) edge (V18);
		\draw[-] (V18) edge (V19); \draw[-] (V19) edge (V23); \draw[-] (V23) edge (V18);
		\draw[-] (V19) edge (V24); \draw[-] (V24) edge (V23); \draw[-] (V23) edge (V19);	
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}[scale=0.5, every node/.style={scale=0.5}]
			\begin{scope}[
				auto, vertice/.style={align=center, draw, circle, minimum width=2em, inner sep=2pt}]
				\node[vertice] (V0) at (0,0) {$0$};
				\node[vertice] (V1) at (2,0) {$1$};
				\node[vertice] (V2) at (4,0) {$2$};
				\node[vertice] (V3) at (6,0) {$3$};
				\node[vertice] (V4) at (8,0) {$4$};
				
				\node[vertice] (V5) at (0,-2) {$5$};
				\node[vertice] (V6) at (2,-2) {$6$};
				\node[vertice] (V7) at (4,-2) {$7$};
				\node[vertice] (V8) at (6,-2) {$8$};
				\node[vertice] (V9) at (8,-2) {$9$};
				
				\node[vertice] (V10) at (0,-4) {$10$};
				\node[vertice] (V11) at (2,-4) {$11$};
				\node[vertice] (V12) at (4,-4) {$12$};
				\node[vertice] (V13) at (6,-4) {$13$};
				\node[vertice] (V14) at (8,-4) {$14$};
	
				\node[vertice] (V15) at (0,-6) {$15$};
				\node[vertice] (V16) at (2,-6) {$16$};
				\node[vertice] (V17) at (4,-6) {$17$};
				\node[vertice] (V18) at (6,-6) {$18$};
				\node[vertice] (V19) at (8,-6) {$19$};
				
				\node[vertice] (V20) at (0,-8) {$20$};
				\node[vertice] (V21) at (2,-8) {$21$};
				\node[vertice] (V22) at (4,-8) {$22$};
				\node[vertice] (V23) at (6,-8) {$23$};
				\node[vertice] (V24) at (8,-8) {$24$};		
			\end{scope}
			
			\draw[-] (V0) edge (V1); \draw[-] (V1) edge (V6); \draw[-] (V6) edge (V0);
			\draw[-] (V0) edge (V6); \draw[-] (V6) edge (V5); \draw[-] (V5) edge (V0);
			\draw[-] (V1) edge (V2); \draw[-] (V2) edge (V6); \draw[-] (V6) edge (V1);
			\draw[-] (V2) edge (V7); \draw[-] (V7) edge (V6); \draw[-] (V6) edge (V2);
			\draw[-] (V2) edge (V3); \draw[-] (V3) edge (V8); \draw[-] (V8) edge (V2);
			\draw[-] (V2) edge (V8); \draw[-] (V8) edge (V7); \draw[-] (V7) edge (V2);
			\draw[-] (V3) edge (V4); \draw[-] (V4) edge (V8); \draw[-] (V8) edge (V3);
			\draw[-] (V4) edge (V9); \draw[-] (V9) edge (V8); \draw[-] (V8) edge (V4);
			
			\draw[-] (V5) edge (V6);  \draw[-] (V6) edge (V10);  \draw[-] (V10) edge (V5);
			\draw[-] (V6) edge (V11); \draw[-] (V11) edge (V10); \draw[-] (V10) edge (V6);
			\draw[-] (V6) edge (V7);  \draw[-] (V7) edge (V12);  \draw[-] (V12) edge (V6);
			\draw[-] (V6) edge (V12); \draw[-] (V12) edge (V11); \draw[-] (V11) edge (V6);
			\draw[-] (V7) edge (V8);  \draw[-] (V8) edge (V12);  \draw[-] (V12) edge (V7);
			\draw[-] (V8) edge (V13); \draw[-] (V13) edge (V12); \draw[-] (V12) edge (V8);
			\draw[-] (V8) edge (V9);  \draw[-] (V9) edge (V14);  \draw[-] (V14) edge (V8);
			\draw[-] (V8) edge (V14); \draw[-] (V14) edge (V13); \draw[-] (V13) edge (V8);
	
			\draw[-] (V10) edge (V11); \draw[-] (V11) edge (V16); \draw[-] (V16) edge (V10);
			\draw[-] (V10) edge (V16); \draw[-] (V16) edge (V15); \draw[-] (V15) edge (V10);
			\draw[-] (V11) edge (V12); \draw[-] (V12) edge (V16); \draw[-] (V16) edge (V11);
			\draw[-] (V12) edge (V17); \draw[-] (V17) edge (V16); \draw[-] (V16) edge (V12);
			\draw[-] (V12) edge (V13); \draw[-] (V13) edge (V18); \draw[-] (V18) edge (V12);
			\draw[-] (V12) edge (V18); \draw[-] (V18) edge (V17); \draw[-] (V17) edge (V12);
			\draw[-] (V13) edge (V14); \draw[-] (V14) edge (V18); \draw[-] (V18) edge (V13);
			\draw[-] (V14) edge (V19); \draw[-] (V19) edge (V18); \draw[-] (V18) edge (V14);
			
			\draw[-] (V15) edge (V16); \draw[-] (V16) edge (V20); \draw[-] (V20) edge (V15);
			\draw[-] (V16) edge (V21); \draw[-] (V21) edge (V20); \draw[-] (V20) edge (V15);
			\draw[-] (V16) edge (V17); \draw[-] (V17) edge (V22); \draw[-] (V22) edge (V16);
			\draw[-] (V16) edge (V22); \draw[-] (V22) edge (V21); \draw[-] (V21) edge (V16);
			\draw[-] (V17) edge (V18); \draw[-] (V18) edge (V22); \draw[-] (V22) edge (V17);
			\draw[-] (V18) edge (V23); \draw[-] (V23) edge (V22); \draw[-] (V22) edge (V18);
			\draw[-] (V18) edge (V19); \draw[-] (V19) edge (V24); \draw[-] (V24) edge (V18);
			\draw[-] (V18) edge (V24); \draw[-] (V24) edge (V23); \draw[-] (V23) edge (V18);	
		\end{tikzpicture}}
		\subfigure[]{
		\begin{tikzpicture}[scale=0.5, every node/.style={scale=0.5}]
			\begin{scope}[
				auto, vertice/.style={align=center, draw, circle, minimum width=2em, inner sep=2pt}]
				\node[vertice] (V0) at (0,0) {$0$};
				\node[vertice] (V1) at (2,0) {$1$};
				\node[vertice] (V2) at (4,0) {$2$};
				\node[vertice] (V3) at (6,0) {$3$};
				\node[vertice] (V4) at (8,0) {$4$};
				
				\node[vertice] (V5) at (0,-2) {$5$};
				\node[vertice] (V6) at (2,-2) {$6$};
				\node[vertice] (V7) at (4,-2) {$7$};
				\node[vertice] (V8) at (6,-2) {$8$};
				\node[vertice] (V9) at (8,-2) {$9$};
				
				\node[vertice] (V10) at (0,-4) {$10$};
				\node[vertice] (V11) at (2,-4) {$11$};
				\node[vertice] (V12) at (4,-4) {$12$};
				\node[vertice] (V13) at (6,-4) {$13$};
				\node[vertice] (V14) at (8,-4) {$14$};
	
				\node[vertice] (V15) at (0,-6) {$15$};
				\node[vertice] (V16) at (2,-6) {$16$};
				\node[vertice] (V17) at (4,-6) {$17$};
				\node[vertice] (V18) at (6,-6) {$18$};
				\node[vertice] (V19) at (8,-6) {$19$};
				
				\node[vertice] (V20) at (0,-8) {$20$};
				\node[vertice] (V21) at (2,-8) {$21$};
				\node[vertice] (V22) at (4,-8) {$22$};
				\node[vertice] (V23) at (6,-8) {$23$};
				\node[vertice] (V24) at (8,-8) {$24$};		
			\end{scope}
			
			\draw[-] (V0) edge (V1); \draw[-] (V1) edge (V6); \draw[-] (V6) edge (V0);
			\draw[-] (V0) edge (V6); \draw[-] (V6) edge (V5); \draw[-] (V5) edge (V0);
			\draw[-] (V1) edge (V2); \draw[-] (V2) edge (V7); \draw[-] (V7) edge (V1);
			\draw[-] (V1) edge (V7); \draw[-] (V7) edge (V6); \draw[-] (V6) edge (V1);
			\draw[-] (V2) edge (V3); \draw[-] (V3) edge (V8); \draw[-] (V8) edge (V2);
			\draw[-] (V2) edge (V8); \draw[-] (V8) edge (V7); \draw[-] (V7) edge (V2);
			\draw[-] (V3) edge (V4); \draw[-] (V4) edge (V9); \draw[-] (V9) edge (V3);
			\draw[-] (V3) edge (V9); \draw[-] (V9) edge (V8); \draw[-] (V8) edge (V3);
			
			\draw[-] (V5) edge (V6);  \draw[-] (V6) edge (V10);  \draw[-] (V10) edge (V5);
			\draw[-] (V6) edge (V11); \draw[-] (V11) edge (V10); \draw[-] (V10) edge (V6);
			\draw[-] (V6) edge (V7);  \draw[-] (V7) edge (V11);  \draw[-] (V11) edge (V6);
			\draw[-] (V7) edge (V12); \draw[-] (V12) edge (V11); \draw[-] (V11) edge (V7);
			\draw[-] (V7) edge (V8);  \draw[-] (V8) edge (V12);  \draw[-] (V12) edge (V7);
			\draw[-] (V8) edge (V13); \draw[-] (V13) edge (V12); \draw[-] (V12) edge (V8);
			\draw[-] (V8) edge (V9);  \draw[-] (V9) edge (V13);  \draw[-] (V13) edge (V8);
			\draw[-] (V9) edge (V14); \draw[-] (V14) edge (V13); \draw[-] (V13) edge (V9);
	
			\draw[-] (V10) edge (V11); \draw[-] (V11) edge (V16); \draw[-] (V16) edge (V10);
			\draw[-] (V10) edge (V16); \draw[-] (V16) edge (V15); \draw[-] (V15) edge (V10);
			\draw[-] (V11) edge (V12); \draw[-] (V12) edge (V17); \draw[-] (V17) edge (V11);
			\draw[-] (V11) edge (V17); \draw[-] (V17) edge (V16); \draw[-] (V16) edge (V11);
			\draw[-] (V12) edge (V13); \draw[-] (V13) edge (V18); \draw[-] (V18) edge (V12);
			\draw[-] (V12) edge (V18); \draw[-] (V18) edge (V17); \draw[-] (V17) edge (V12);
			\draw[-] (V13) edge (V14); \draw[-] (V14) edge (V19); \draw[-] (V19) edge (V13);
			\draw[-] (V13) edge (V19); \draw[-] (V19) edge (V18); \draw[-] (V18) edge (V13);
			
			\draw[-] (V15) edge (V16); \draw[-] (V16) edge (V20); \draw[-] (V20) edge (V15);
			\draw[-] (V16) edge (V21); \draw[-] (V21) edge (V20); \draw[-] (V20) edge (V15);
			\draw[-] (V16) edge (V17); \draw[-] (V17) edge (V21); \draw[-] (V21) edge (V16);
			\draw[-] (V17) edge (V22); \draw[-] (V22) edge (V21); \draw[-] (V21) edge (V17);
			\draw[-] (V17) edge (V18); \draw[-] (V18) edge (V22); \draw[-] (V22) edge (V17);
			\draw[-] (V18) edge (V23); \draw[-] (V23) edge (V22); \draw[-] (V22) edge (V18);
			\draw[-] (V18) edge (V19); \draw[-] (V19) edge (V23); \draw[-] (V23) edge (V18);
			\draw[-] (V19) edge (V24); \draw[-] (V24) edge (V23); \draw[-] (V23) edge (V19);	
		\end{tikzpicture}}
	\centering
	\caption{Darstellung von drei verschiedenen Varianten der Vollvernetzung.}
	\label{fig:FULL_MESH}
\end{figure}

Die Anzahl der Vertices entspricht der Anzahl der insgesamt gegebenen Bildpunkte.
Die x- und y-Komponenten lassen sich aus der bekannten Auflösung vorausberechnen und
müssen im Falle einer Auflösungsänderung neu bestimmt werden.
Für jeden Vertex wird die z-Komponente mit Hilfe der Pixelwerte aus dem Tiefenbild
während der Bildsynthese gesetzt.
Die Anzahl der Dreiecke lässt sich dabei wie folgt berechnen: $2 (w-1) (h-1)$.

Problematisch bei diesem Verfahren ist, dass die Anzahl der Dreiecke von der Auflösung
abhängt und der Rechenaufwand der clientseitigen Bildsynthese linear mit der Auflösung steigt.

\section{Delaunay-Triangulierung}

Die zweite in dieser Arbeit untersuchte Variante zur Erzeugung eines Dreiecksnetzes aus einem Tiefenbild $D$,
besteht in der serverseitigen Erzeugung einer adaptiven Vernetzung.
Prinzipiell, lässt sich die Vorgehensweise in drei Schritte unterteilen:
Im ersten Schritt wird eine Menge von Punkten $P \subset D$ definiert.
Dabei muss die Menge $P$ so gewählt werden, 
dass die Werteverläufe des Tiefenbildes möglichst optimal wiedergegeben werden.
Der zweite Schritt besteht in der Vernetzung der Punkte $p \in P$ zu Dreiecken.
Das dabei eingesetzte Verfahren ist die Delaunay-Triangulierung.
Abschließend kann das erzeugte Netz in einem dritten Schritt weiter verfeinert werden.

Entscheidend für das Ergebnisnetz und für die Geschwindigkeit des gesamten Verfahrens ist die Wahl der Punktmenge $P$.
Das Ziel bei der Verteilung der Punktemenge $P$ ist es, eine hohe Punktdichte im Bereich von
Kanten und gekrümmten Flächen zu erzielen.
Im Gegensatz dazu sollten planare Regionen möglichst keine Punkte enthalten, 
weil diese mit wenigen Dreiecken approximiert werden können.
Ausgangspunkt für die Erzeugung der Punktmenge $P$ sind die Gradienten des Tiefenbildes $\nabla_x$ und $\nabla_y$. 
Die Gradienten werden mit Hilfe des Sobel-Operators berechnet. 
Dazu wird die erste Ableitung berechnet und gleichzeitig wird die dazu orthogonale Richtung geglättet.
Mit Hilfe einer Faltungsmatrix der Größe $3 \times 3$ lassen sich die Gradienten berechnen:

\begin{align*}
\nabla_x &= \begin{bmatrix} 1 & 0 & -1 \\ 2 & 0 & -2 \\ 1 & 0 & -1 \end{bmatrix} \ast D, &
\nabla_y &= \begin{bmatrix} 1 & 2 & 1 \\ 0 & 0 & 0 \\ -1 & -2 & -1 \end{bmatrix} \ast D.
\label{eq:SOBEL_GRAD}
\end{align*}

Auf diese Weise entstehen für ein Tiefenbild zwei Gradientenbilder, wie in Abbildung \ref{fig:gradient_images}
dargestellt.
Zur Erzeugung der Punktmenge $P$ wurden zwei Verfahren untersucht, die im Folgenden näher betrachtet werden. 

\begin{figure}[H]
	\subfigure[]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/D10/L0.0/I0.0/_pre/gx.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/D10/L0.0/I0.0/_pre/gy.png}}
	
	\subfigure[]{\includegraphics[width=.49\textwidth]{../results/6/512x512_Delaunay/D10/L0.0/I0.0/_pre/gx.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{../results/6/512x512_Delaunay/D10/L0.0/I0.0/_pre/gy.png}}
	\caption{Gradientenbilder beider Datensätze vom jeweils ersten Tiefenbild.}
	\label{fig:gradient_images}
\end{figure}

\subsection{Quadtree}

Die erste in dieser Arbeit vorgestellte Methode, zur Erzeugung der Punktmenge $P$,
basiert auf einer Quadtree-Datenstruktur.
Ein Quadtree ist eine Baumdatenstruktur, in der die Anzahl der Kindknoten, eines Knotens auf vier Kindknoten
beschränkt wird.
Im Rahmen dieser Arbeit repräsentiert jeder Knoten eine rechteckige Region $R$ des Tiefenbildes $D$.
Eine Region $R$ wird durch seine Eckpunkte definiert.
Um die Baumdatenstruktur zu erzeugen, wird ein Wurzelknoten definiert, dessen Region $R = (0, 0, w-1, h-1)$ den
Ausmaßen des Tiefenbildes $D$ entspricht.
Im Anschluss wird die Region des Wurzelknotens in vier gleichgroße Teilregionen zerlegt.
Diese Teilregionen sind die Kindknoten des Wurzelknotens.
Alle Kindknoten werden auf diese Weise sukzessive weiter unterteilt, bis die Tiefe des erzeugten Baumes
eine maximale Baumtiefe $t_{max}$ erreicht.
Die Kindknoten der Baumtiefe $t_{max}$ enthalten selbst keine weiteren Kindknoten und
werden als Blattknoten bezeichnet, die Regionen die sie repräsentieren als Blattregionen.
Die maximale Tiefe des Quadtrees ist dabei invers proportional zur Breite der Blattregionen.
Mit dem Parameter $t_{max}$ kann die Qualität und die Kompression des erzeugten Netzes
sowie der Berechnungsaufwand skaliert werden.
Die erzeugte Baumdatenstruktur hängt von der Auflösung der Tiefenbilder ab
und muss nur neu erzeugt werden, wenn sich die Auflösung oder der Parameter $t_{max}$ ändert.

Im nächsten Schritt wird mit Hilfe der Baumdatenstruktur die Punktmenge $P$ erzeugt.
Zu diesem Zweck wird der Baum, beginnend mit den Blattknoten, zum Wurzelknoten traversiert.
Mit Hilfe der Gradienten kann die Region $R$ eines Knoten auf planarität getestet werden.
Ist eine Region $R$ nicht planar, dann werden die Eckpunkte von $R$ zur Menge $P$ hinzugefügt.

Um zu überprüfen, ob eine Region $R$ als planar bezeichnet werden kann, lässt sich
mit Hilfe der Differenz zwischen dem maximalen und dem minimalen Wert der Gradienten innerhalb von $R$ bestimmten:

\begin{align}
c_x &= \max\limits_{R} \nabla_x - \min\limits_{R} \nabla_x \\
c_y &= \max\limits_{R} \nabla_y - \min\limits_{R} \nabla_y .
\end{align}

Wenn entweder $c_x$ oder $c_y$ größer als ein zuvor definierter Schwellwert ist, dann
ist die Region $R$ nicht planar und die Eckpunkte werden der Menge $P$ hinzugefügt.
Die Werte für $c_x$ und $c_y$ der inneren Konten lassen sich effizient aus den bereits berechneten
maximalen und minimalen Gradienten seiner Kindknoten berechnen.

Die Wahl des Schwellwerts ist entscheidend für die Anzahl der eingefügten Punkte in $P$.
Dieser kann adaptiv gewählt werden, um die Komplexität des Dreiecksnetzes anzupassen.

Für den eigentlichen Planaritätstest unterscheidet sich dieser Schwellwert
in Abhängigkeit, ob es sich um einen inneren oder einen Blattknoten handelt.
Der Schwellwert für die Blattknoten wird mit $l$ bezeichnet und der für die inneren Knoten mit $i$.
Blattknoten sollten vorrangig Tiefenuntersprünge, Kanten detektieren und somit die Kontur der dargestellten Objekte
kennzeichnen.
Innere Knoten dagegen repräsentieren die Oberfläche der Objekte und werden gesetzt, um Verläufe von nicht planaren
Flächen abzubilden zu können. 
Weil Tiefensprünge größere Gradienten zur Folge haben als gekrümmte Oberflächen, 
sollte der Schwellwert $i$ für die inneren Knoten kleiner sein als der Schwellwert $l$ für die Blattknoten, $i < l$.
Die Werte von $i$ und $l$ liegen im Intervall $[0,1]$.

Das Ergebnis der Traversierung des Baums ist eine Menge von Punkten $P$, die sich aus den Eckpunkten der getesteten
Regionen zusammensetzt, in denen die Gradientdifferenzen den entsprechenden Schwellwert überschreitet.

\begin{figure}
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/seed_7_D9_5_4.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/seed_7_D9_5_4_pre.png}}
	\caption{Szene \textit{TestSpheres}, Baumtiefe 9, l=5, i=4}
\end{figure}

Diese Punktmenge $P$ kann weiter reduziert werden, indem getestet wird, ob ein Punkt $p \in P$ zum Hintergrund gehört.
Das ist der Fall, wenn der Tiefenwert des Tiefenbildes an Stelle $p$ dem maximalen Tiefenwert entspricht.
Zur Erinnerung: Die Tiefenwerte liegen linear zwischen den beiden Clippingebenen, wobei ein großer Wert bedeutet,
dass dieser nahe der Bildschirmebene liegt.

\subsection{Floyd-Steinberg}

Der zweite in dieser Arbeit vorgestellte Ansatz, zur Erzeugung der Punktmenge $P$ basiert auf einem Fehler-Diffusionsverfahren.
Im ersten Schritt wird aus den beiden Gradientenbildern $\nabla_x, \nabla_y$ ein 
Merkmalsbild $\sigma$ erzeugt:

\begin{equation}
	\sigma_d = \left( \frac{\parallel \nabla d \parallel}{A} \right)^\gamma.
	\label{eq:featureMap}
\end{equation}

Dabei entspricht der Nenner von \ref{eq:featureMap} der Länge des Gradientenvektors $\nabla d$, des Pixels $d \in D$.
Dieser wird mit $A$, dem größtmöglichen Wert von $\parallel \nabla d \parallel$, normiert.
Der Parameter $\gamma \in [0,1]$ wird genutzt, um die Ausprägung von schwachen 
Kanten im Merkmalsbild $\sigma$ zu erhöhen.

Um aus dem Merkmalsbild $\sigma$ die Punktmenge $P$ zu erzeugen, kommt der Floyd-Steinberg-Algorithmus zum Einsatz. 
Bei dem Floyd-Steinberg-Algorithmus handelt es sich um einen einfachen und effizienten Dithering-Algorithmus,
der auf einem, Fehler-Diffusionsverfahren fußt.
Das Merkmalsbild wird mit Hilfe des Schwellwerts $\delta$ binarisiert.
Zu diesem Zweck wird das Merkmalsbild $\sigma$ Pixel für Pixel zeilenweise durchlaufen.
Der betrachtete Pixel wird mit einem Schwellwert $\delta$ verglichen.
Wenn der Wert des Pixels größer als der Schwellwert ist, 
dann wird der Wert des Pixels mit $\delta$, andernfalls mit $0$ ersetzt.
Zudem wird durch die Binarisierung resultierende Quantisierungsfehler des Pixels $d \in D$ entsprechend der Abbildung \ref{fig:FloydSteinberg_Quantisierungsfehler} auf die benachbarten Pixel verteilt. 

\begin{figure}[H]
	\begin{tikzpicture}
		\tikzstyle{Element} = [draw=black,
	    minimum width=1.5cm, minimum height=1.5cm, node distance=1.5cm]
		\node[Element, fill=blue!20] (A) {d};
		\node[Element, right of=A] (B) {$\frac{7}{16}$};
		\node[Element, below of=A] (C) {$\frac{5}{16}$};
		\node[Element, below of=B] (D) {$\frac{1}{16}$};
		\node[Element, left  of=C] (E) {$\frac{3}{16}$};
	\end{tikzpicture}
	\centering
	\caption{Darstellung der gewichteten Verteilung des Quantisierungsfehlers \cite{wiki:001}.}
	\label{fig:FloydSteinberg_Quantisierungsfehler}
\end{figure}

Dadurch lässt sich die Verteilung des Quantisierungsfehlers ohne einen zusätzlichen Puffer in einem einzigen Durchlauf berechnen.
Das folgende Pseudocodebeispiel \ref{lst:floyd_steinberg} verdeutlicht das Verfahren:

\begin{lstlisting}[numbers=left,
				   mathescape=true,
				   xleftmargin=0.1\textwidth,
				   captionpos=b,
				   caption={Floyd-Steinberg-Algorithmus \cite{wiki:001}},label={lst:floyd_steinberg}]
for each y
	for each x
	   oldpixel        := pixel[x][y]
	   newpixel        := (pixel[x][y] > $\delta$) ? $\delta$ : 0
	   pixel[x][y]     := newpixel
	   quant_error     := oldpixel - newpixel
	   pixel[x+1][y  ] := pixel[x+1][y  ] + quant_error * 7 / 16
	   pixel[x-1][y+1] := pixel[x-1][y+1] + quant_error * 3 / 16
	   pixel[x  ][y+1] := pixel[x  ][y+1] + quant_error * 5 / 16
	   pixel[x+1][y+1] := pixel[x+1][y+1] + quant_error * 1 / 16
\end{lstlisting}

Immer wenn die Bindung erfüllt wird und der Wert eines Pixels auf $\delta$ gesetzt wird,
dann wird die Menge $P$ mit der Position des gerade bearbeiteten Pixels erweitert.
Die Abbildung \ref{fig:feature_Maps} zeigt verschiedene bereits auf $\delta$ und $0$ reduzierte
Merkmalsbilder $\sigma$.

Ein Vorteil dieses Verfahrens ist die effiziente Erzeugung der Menge $P$.
Mit Hilfe der beiden Parameter $\gamma, \delta$ lässt sich die Anzahl der Punktmenge $P$ variieren.
Dabei spielt insbesondere $\delta$ eine entscheidende Rolle, da durch diese Größe die Punktdichte
angepasst werden kann.
Wenn $\delta$ kleine Werte annimmt, dann wird die Punktdichte erhöht und im Fall großer Werten reduziert.

\begin{figure}[H]
	\subfigure[$\gamma = 0.2$]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/T0.5/G0.2/featuremap.png}}
	\subfigure[$\gamma = 0.4$]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/T0.5/G0.4/featuremap.png}}
	\subfigure[$\gamma = 0.6$]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/T0.5/G0.6/featuremap.png}}
	\subfigure[$\gamma = 1.0$]{\includegraphics[width=.49\textwidth]{../results/7/512x512_Delaunay/T0.5/G1.0/featuremap.png}}
	\caption{Die Bilder a bis d zeigen das Merkmalsbild in Abhängigkeit des Parameters $\gamma$ bei einem 			 
			 festgesetzten Schwellwert von $0.5$.}
	\label{fig:feature_Maps}
\end{figure}

\subsection{Erzeugung des Netzes}

Die aus den beiden Methoden erzeugten Punkte $p \in P$ können jetzt mit Hilfe der Delaunay-Triangulierung
zu einem Dreiecksnetz miteinander verbunden werden.
In dieser Arbeit wird zu diesem Zweck die Delaunay-Triangulierung aus dem opencv-Framework verwendet.

\subsection{Netzoptimierung}

Das auf diese Weise entstandene Netze können, in Abhängigkeit der Eingabedaten, zwei arten von Artefakten enthalten.
Zum einen können Dreiecke falsche Tiefenregionen approximieren, weil nur
die Eckpunkte der jeweiligen Regionen $R$ zur Konstruktion der Dreiecke genutzt werden.
Zum anderen können Dreiecke über Tiefensprüngen liegen, wodurch Kanten nicht korrekt vom Netz abgebildet werden.
Diese Art von Artefakte kommen zustande, wenn die Blattregionen zu große Bildregionen repräsentieren.
Um die Artefakte zu reduzieren, werden nicht valide Dreiecke nochmals unterteilt oder verworfen.

Die Validität eines Dreiecks wird anhand seiner Kanten bestimmt.
Eine Kante wird als nicht valide Kante bezeichnet, wenn die Tiefenwerte
einiger von ihr überspannten Pixel abweicht, oder die 3D Richtung der Kante
sich dem Lot der Bildebene nährt, während gleichzeitig eine bestimmte Länge in der xy-Ebene überschritten wird.

Die Eckpunkte der zu prüfenden Kante, werden im folgenden mit $p_1$ und $p_2$ bezeichnet.
Der Punkt $p_m$ bezeichnet dabei den Mittelpunkt der Kante $p_1 p_2$.

\begin{equation}
	\frac{d_{p_1} + d_{p_2}}{2} - d_{p_m} < \varepsilon
\end{equation}

Eine Kante ist nicht valide, wenn der eigentliche Tiefenwert $D(p_m)$ 
In der Gleichung \ref{eq:EDGE_VALID} approximiert der erste Term das Verhältnis,
zwischen dem Betrag des Tiefenunterschieds von $p_1$ und $p_2$
zu der Länge der Kante projiziert auf die $xy$-Ebene.

\begin{equation}
\frac{\mid d_{p_1} - d_{p_2} \mid}{\parallel p_1 - p_2 \parallel (d_{p_1} + d_{p_2})} < \alpha
\label{eq:EDGE_VALID}
\end{equation}

Ist der Wert des ersten Terms der Gleichung \ref{eq:EDGE_VALID} einer Kannte größer 
als der Schwellwert $T_{angle}$, dann steht diese Kante nahezu senkrecht auf der
Bildebene und sie liegt mit hoher Wahrscheinlich über einen Tiefensprung. 
Eine Kante auf die das zutrifft wird als nicht valide bezeichnet.
Enthält ein Dreieck mindestens zwei Kanten die valide sind, wird es direkt zum
endgültigen Dreiecksnetz hinzugefügt.
Wenn ein Dreieck dagegen mehr als zwei nicht valide Kanten enthält,
wird es weiter unterteilt.

Zwei Bildpunkte $p_1$ und $p_2$ werden als verbindbar bezeichnet,
wenn alle Bildpunkte zwischen $p_1$ und $p_2$ valide Tiefenwerte
besitzen und ihre Tiefe sich zum größten Teil linear ändert.
Um Rechenzeit zu sparen wird empfohlen nur den Median $p_m$ zwischen
$p_1$ und $p_2$ zu testen.
Eine Strecke wird als Verbindbar bezeichnet, wenn sie die folgende Gleichung
erfüllt:

\begin{equation}
\mid (d(p_2) - d(p_m)) - (d(p_m) - d(p_1)) \mid < \beta
\label{eq:EDGE_JOIN}
\end{equation}.

Um ein Dreieck zu unterteilen muss eine Fallunterscheidung durchgeführt werden.
Hat das Dreieck nur eine valide Kante $p_1 p_2$, dann müssen die anderen beiden
Kanten wie in der Abbildung \ref{fig:1VALID_EDGES} geteilt werden und es entstehen
aus dem ursprünglichen Dreieck drei neue Dreiecke.

\begin{figure}[th]
	\subfigure[]{
	\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6}]
		\draw[fill=gray!50] (0, -5) -- (0, 2) -- (2, 2) -- (2, 1) -- (5, 1) -- (5, 0) --(7, 0) -- (7, -1) -- (8, -1) -- (8, -2) -- (9, -2) -- (9, -5) -- cycle;
		
		\begin{scope}[
			auto, vertex/.style={align=center, draw, fill=white, circle, line width=0.5mm, minimum width=2em, inner sep=2pt}]
			\node[vertex] (V1) at (1, -2) {$p_1$};
			\node[vertex] (V2) at (7, -3) {$p_2$};
			\node[vertex] (V3) at (5, 4) {$p_3$};
		\end{scope}
		
		\draw[-, line width=0.5mm] (V1) edge (V2);
		\draw[-, line width=0.5mm] (V2) edge (V3);
		\draw[-, line width=0.5mm] (V1) edge (V3);
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6}]
		\draw[fill=gray!50] (0, -5) -- (0, 2) -- (2, 2) -- (2, 1) -- (5, 1) -- (5, 0) --(7, 0) -- (7, -1) -- (8, -1) -- (8, -2) -- (9, -2) -- (9, -5) -- cycle;
		
		\begin{scope}[
			auto, vertex/.style={align=center, draw, fill=white, circle, line width=0.5mm, minimum width=2em, inner sep=5pt}]
			\node[vertex] (V1) at (1, -2) {$p_1$};
			\node[vertex] (V2) at (7, -3) {$p_2$};
			
			\node[vertex] (V13) at (2.7, 0.5) {$p_1'$};
			\node[vertex] (V23) at (6.3, -0.5) {$p_2'$};
			
			\node[vertex] (V3) at (5, 4) {$p_3$};
			
			\node[vertex] (V31) at (3.4, 1.5) {$p_3'$};
			\node[vertex] (V32) at (6, 0.5) {$p_3''$};
		\end{scope}
		
		\draw[-, line width=0.5mm] (V1) edge (V2);
		\draw[-, line width=0.5mm] (V1) edge (V13);
		\draw[-, line width=0.5mm] (V2) edge (V23);
		
		\draw[-, line width=0.5mm] (V13) edge (V23);
		\draw[-, line width=0.5mm] (V13) edge (V2);
		
		\draw[-, line width=0.5mm] (V3) edge (V31);
		\draw[-, line width=0.5mm] (V3) edge (V32);
		\draw[-, line width=0.5mm] (V31) edge (V32);
	\end{tikzpicture}}
	\centering
	\caption{Die Bilder a und b zeigen die Unterteilung des Dreiecks $p_1 p_2 p_3$, 
	wenn die zwei Kanten $p_1 p_3$, $p_2 p_3$ nicht valide sind.}
	\label{fig:1VALID_EDGES}
\end{figure}

Dazu werden vier neue Vertices iterativ entlang der alten Strecken eingefügt:

Der Vertex $p_1'$ ist der von Punkt auf der Strecke $p_3 p_1$, der am weitesten von $p_1$
entfernt liegt und mit dem Punkten $p_1$ und $p_2'$ verbindbar ist.

Der Vertex $p_2'$ ist der von Punkt auf der Strecke $p_3 p_2$, der am weitesten von $p_2$
entfernt liegt und mit dem Punkten $p_2$ und $p_1'$ verbindbar ist.

Der Vertex $p_3'$ ist der von Punkt auf der Strecke $p_3 p_1$, der am weitesten von $p_3$
entfernt liegt und mit dem Punkt $p_3$ verbindbar ist.

Der Vertex $p_3''$ ist der von Punkt auf der Strecke $p_3 p_2$, der am weitesten von $p_3$
entfernt liegt und mit dem Punkt $p_3$ verbindbar ist.

Anschließend wird das Dreieck $p_3 p_3' p_3''$ zum endgültigen Dreiecksnetz hinzugefügt.
Um die anderen beiden Dreiecke einzufügen muss eine weitere Fallunterscheidung durchgeführt
werden.
Wenn die Strecke $p_1 p_2'$ kleiner ist als $p_2 p_1'$, dann werden die Dreiecke $p_1 p_2 p_2'$,
$p_1 p_2' p_1'$ zu dem finalen Netz hinzugefügt,
andernfalls die beiden Dreiecke $p_1 p_2 p_1'$ und $p_2 p_2' p_1'$.

In dem Fall, das alle drei Kanten nicht valide sind, werden sechs neue Vertices eingefügt,
die Abbildung \ref{fig:0VALID_EDGES} verdeutlicht diesen Fall. 
Die Berechnung aller Vertices geschieht analog zu dem Vertex $p_3'$ aus dem vorhergehenden Betrachtung mit
einer validen Kante.


\begin{figure}[th]
	\subfigure[]{
	\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6}]
		\draw[fill=gray!30] (0, -5) -- (0, 2) -- (2, 2) -- (2, 1) -- (3, 1) -- (3, -5) -- cycle;
		
		\draw[fill=gray!80] (4, -5) -- (4, 1) -- (5, 1) -- (5, 0) -- (7, 0) -- (7, -1) -- (8, -1) -- (8, -2) -- (9, -2) -- (9, -5) -- cycle;
		
		\begin{scope}[
			auto, vertex/.style={align=center, draw, fill=white, circle, line width=0.5mm, minimum width=2em, inner sep=2pt}]
			\node[vertex] (V1) at (1, -2) {$p_1$};
			\node[vertex] (V2) at (7, -3) {$p_2$};
			\node[vertex] (V3) at (5, 4) {$p_3$};
		\end{scope}
	
		\draw[-, line width=0.5mm] (V1) edge (V2);
		\draw[-, line width=0.5mm] (V2) edge (V3);
		\draw[-, line width=0.5mm] (V1) edge (V3);	
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6}]
		\draw[fill=gray!30] (0, -5) -- (0, 2) -- (2, 2) -- (2, 1) -- (3, 1) -- (3, -5) -- cycle;
		
		\draw[fill=gray!80] (4, -5) -- (4, 1) -- (5, 1) -- (5, 0) -- (7, 0) -- (7, -1) -- (8, -1) -- (8, -2) -- (9, -2) -- (9, -5) -- cycle;
		
		\begin{scope}[
			auto, vertex/.style={align=center, draw, fill=white, circle, line width=0.5mm, minimum width=2em, inner sep=2pt}]
			\node[vertex] (V1) at (1, -2) {$p_1$};
			\node[vertex] (V2) at (7, -3) {$p_2$};
			
			\node[vertex] (V13) at (2.6, 0.4) {$p_1''$};
			\node[vertex] (V12) at (2.6, -2.3) {$p_1'$};
			
			\node[vertex] (V23) at (6.3, -0.5) {$p_2'$};
			\node[vertex] (V21) at (4.5, -2.6) {$p_2''$};
			
			\node[vertex] (V3) at (5, 4) {$p_3$};
			
			\node[vertex] (V31) at (3.4, 1.5) {$p_3'$};
			\node[vertex] (V32) at (6, 0.5) {$p_3''$};
		\end{scope}
		
		\draw[-, line width=0.5mm] (V1) edge (V12);
		\draw[-, line width=0.5mm] (V1) edge (V13);
		\draw[-, line width=0.5mm] (V12) edge (V13);
		\draw[-, line width=0.5mm] (V2) edge (V23);
		\draw[-, line width=0.5mm] (V2) edge (V21);
		\draw[-, line width=0.5mm] (V21) edge (V23);
		
		\draw[-, line width=0.5mm] (V3) edge (V31);
		\draw[-, line width=0.5mm] (V3) edge (V32);
		\draw[-, line width=0.5mm] (V31) edge (V32);
	\end{tikzpicture}}
	\centering
	\caption{Die Bilder a und b zeigen die Unterteilung des Dreiecks $p_1 p_2 p_3$, 
			 wenn keine Kante valide ist.}
	\label{fig:0VALID_EDGES}
\end{figure}

Zu beachten ist, dass jedes neu erzeugte Dreieck auf Kollinearität zu überprüfen
und gegebenenfalls zu verwerfen.

Die Pixelpositionen, in den Gleichungen \ref{eq:EDGE_VALID} und \ref{eq:EDGE_JOIN} werden in Texturkoordinaten angegeben und die Farbwerte der Pixel auf das Intervall $[0,1]$ transformiert.
Zu beachten ist, dass der Parameter $\alpha$ von der Baumtiefe abhängt.

\begin{figure}
	\centering
	\subfigure[$\alpha = 0.1, \beta = 0.1$]{\includegraphics[width=.3\textwidth]{img/delaunay_A01_J01.png} }
	\subfigure[$\alpha = 1, \beta = 0.1$]{\includegraphics[width=.3\textwidth]{img/delaunay_A10_J01.png} }
	\subfigure[$\alpha = 10, \beta = 0.1$]{\includegraphics[width=.3\textwidth]{img/delaunay_A100_J01.png} }
	
	\subfigure[$\alpha = 10, \beta = 0.3$]{\includegraphics[width=.3\textwidth]{img/delaunay_A100_J03.png} }
	\subfigure[$\alpha = 10, \beta = 0.4$]{\includegraphics[width=.3\textwidth]{img/delaunay_A100_J04.png} }
	\subfigure[$\alpha = 10, \beta = 1.0$]{\includegraphics[width=.3\textwidth]{img/delaunay_A100_J10.png} }
	\caption{Auswirkung der Parameter auf die Nachbearbeitung. Das Netz wurde mit der \textit{Quadtree}-Methode erzeugt, 
	dazu wurde $t_{max} = 8, l = 0.7, i = 0.6$ gewählt.}
	\label{fig:param_env}
\end{figure}

Dabei zeigt die Abbildung \ref{fig:param_env} den Einfluss von $\alpha$ und $\beta$ bei der Nachbearbeitung.
Rot markierte Kanten sind nicht valide und werden nicht zum endgültigen Netz hinzugefügt.
Alle grünen Kanten, gehören zu Dreiecken die aus einem Dreieck, ohne valide Kante erzeugt wurden.
Analog dazu wurden Dreiecke, hervorgehoben durch blaue Kanten aus Dreiecken erzeugt mit nur einer
validen Kante.
Kollineare Dreiecke fallen zu Schwarzen Kanten oder Punkten zusammen.

Wenn die Parameter $\alpha = 0$ und $\beta = 0$ gewählt werden, degeneriert das Netz.
Es ist zu erkennen, das mit größer werden $\alpha$ der Einfluss auf gekrümmte Oberflächen abnimmt.
Mit dem Parameter $\beta$ lässt sich die Verbindungsneigung beeinflussen.

Die Abbildung \ref{fig:refined_mesh_1} zeigt ein komplettes nachbearbeitetes Dreiecksnetz.

\begin{figure}
	\includegraphics[width=\textwidth]{../results/7/512x512_Delaunay/D9/L0.5/I0.4/A1.0/J0.1/_pre/delaunay.png}
	\caption{Nachbearbeites Netz des ersten Frames aus dem \textit{TestSpheres}-Datensatz.
			 Das Netz wurde mit der \textit{Quadtree}-Methode erzeugt, dazu wurde $t_{max} = 9, l = 0.5, i = 0.4, \alpha = 1.0, \beta = 0.1$ gewählt.}
	\label{fig:refined_mesh_1}
\end{figure}


\chapter{Implementierung}

Die Client-Anwendung ist eine Browser basierte Web-Anwendung, die mit dem Server
über das WebSocket-Protokoll kommuniziert.
Dabei handelt es sich um ein auf TCP basierendes Netzwerkprotokoll,
das eine Bidirektionale Verbindung zwischen den Verbindungsteilnehmern erlaubt,
ohne auf Methoden wie Long Polling zurückgreifen zu müssen.
Die klientseitge Extrapolation der Bilddaten wird mit Hilfe von WebGL durchgeführt wird.
Bei WebGL handelt es sich um eine Bibliothek die von modernen Browsern zur Verfügung gestellt wird,
um eine Hardware beschleunigte Bildsynthese zu ermöglichen.
Der Vorteil dieser Technologie ist die Unabhängigkeit der Anwendung im Bezug,
zur Plattform und dem Gerät, in Kombination mit einer hohen Rechengeschwindigkeit.

Diese Kapitel wird dabei in zwei Hauptbereiche unterteilt.
Im ersten, werden Details über die Kommunikation zwischen Client und Server behandelt.
Der zweite Abschnitt beschäftigt sich mit Implementierungsspezifischen Details der
Algorithmen.

\section{Details zur Kommunikation}

Die Server-Anwendung wurde mit der Sprache c++ entwickelt.
Dabei wird auf die Implementierung der WebSocket-Serverkomponente
aus dem QT-Framework zurückgegriffen.
Der Server-Prozess besteht aus einem Thread.
Zur Verwaltung der Anfragen wird das Event-Managementsystem von QT verwendet. 
Beim Start der Serveranwendung werden die Szenen geladen.
Aus diesen wird eine \textit{Playlist} erstellt, diese vereint die Informationen aller Szenen.
Im Anschluss daran wird Standardparameterkonfiguration geladen
und der Server wartet darauf, dass sich ein Client verbindet.

Die Kommunikation zwischen Server- und die Client-Komponente basiert auf dem
JSON-RPC 2.0 Protokoll.
Die Abkürzung JSON-RPC steht für \textit{JavaScript Object Notation Remote Procedure Call}.
Es handelt sich dabei, um ein Protokoll, das den Aufbau und die Nominatur von Nachrichten beschreibt. 
Im speziellen um Nachrichten, die dazu dienen, dass der Kommunikationsteilnehmer bestimmte 
Methoden mit bestimmten Parameterkonfigurationen zu starten.
Es basiert auf dem Textbasierten Datenformat JSON.
Nachrichten werden in Anfragen und Antworten unterteilt.
Mit Hilfe einer $id$ lassen sich Nachrichten bei asynchroner Kommunikation zuordnen.
Es werden drei verschiedene Typen von Anfragen unterschieden, \textit{Request}, \textit{Notification}  und \textit{Batch Request}.
Ein \textit{Request} ist eine Anfrage, welche die Antwort eines Kommunikationsteilnehmers verlangt.
Diese Form der Anfragen, kann zu Synchronisierten Nachrichtenübertragung genutzt werden. 
Im Gegensatz dazu, entfällt bei einer \textit{Notification} die $id$, weil keine Antwort verlangt wird.
Der \textit{Batch Request} fast eine Menge von \textit{Requests} und \textit{Notifications} in
eine einzige Anfrage zusammen.

In dieser Arbeit implementierte Variante von JSON-RPC 2.0, 
wird auf Anfragen vom Typ \textit{Request} beschränkt,
weil die gesamte Kommunikation synchronisiert stattfindet.

Eine JSON-RPC-Anfrage ist ein JSON-Objekt, das sich aus vier Teilen zusammensetzt.
Der erste ist ein String mit der JSON-RPC Version, gefolgt vom Namen der aufzurufenden Methode.
Im Anschluss folgt ein JSON-Objekt, das die Parameter der Aufzurufenden Methode enthält
und zum Schluss kommt die $id$ der Anfrage.
Als Beispielanfrage soll der Aufruf der Methode \textit{resize} dienen.
Möchte der Client die Auflösung ändern schickt er die Anfrage, dem Beispiel \ref{lst:jsonrpc_request_resize}
entsprechend zum Server.

\begin{lstlisting}[numbers=left,mathescape=true,xleftmargin=0.1\textwidth,captionpos=b,caption={RPC-Request},label={lst:jsonrpc_request_resize}]
{
	"jsonrpc" 	: "2.0",
	"method"	: "resize",
	"params"	: [512, 512],
	"id",		: 0
}
\end{lstlisting}

Hat der Server die Anfrage empfangen, ruft dieser darauf hin die Methode \textit{resize} mit den entsprechenden Parametern aus der Anfrage auf.
Im Anschluss daran, wird eine Antwort zurückgesendet.
Eine JSON-RPC-Antwort ist ebenfalls ein JSON-Objekt, dass aus drei Teilen besteht.
Der erste Teil ist ebenfalls die JSON-RPC Version als String kodiert.
Der zweite Teil enthält den Rückgabewert in Form eines JSON-Objektes
und zum Schluss folgt die $id$ der Anfrage, 
wie im Beispiel \ref{lst:jsonrpc_response_resize} demonstriert
 
\begin{lstlisting}[numbers=left,mathescape=true,xleftmargin=0.1\textwidth,captionpos=b,caption={RPC-Response},label={lst:jsonrpc_response_resize}]
{
	"jsonrpc" 	: "2.0",
	"result"	: [512, 512],
	"id",		: 0
}
\end{lstlisting}

Der Server stellt eine Menge von Methoden zur Verfügung, die durch den Client initiiert,
von dem Serverprozess ausführt werden.

Eine Beispielkommunikation, dargestellt im Sequenzdiagramm \ref{fig:Squenzdiagram} veranschaulicht
den Remote-Aufruf verschiedener Methoden.

\begin{figure}[H]
	\begin{tikzpicture}
		\tikzstyle{Komponent} = [draw=black, minimum width=2.5cm, minimum height=1.5cm]
		\tikzstyle{IsActive} = [draw=black, fill=white, minimum width=0.2cm, minimum height=0.5cm] % node distance=1.5cm
		\node[Komponent] (SERVER) at (0, 0) {:Server};
		\node[Komponent] (CLIENT) at (10, 0) {:Client};
		\draw[thick, dashed] (SERVER) -- (0, -13);
		\draw[thick, dashed] (CLIENT) -- (10, -13);
		
		\node[IsActive] (S1) at (0, -2) {};
		\node[IsActive] (C1) at (10, -2) {};
		\draw[thick, ->] (C1.north west) -- (S1.north east) node [midway, above] {Connect};
		\draw[thick, dashed, ->, >=stealth] (S1.south east) -- (C1.south west) node [midway, below] {Connected};
		
		\node[IsActive] (S2) at (0, -4) {};
		\node[IsActive] (C2) at (10, -4) {};
		\draw[thick, ->] (C2.north west) -- (S2.north east) node [midway, above] { method : getPlaylist, id : 0};
		\draw[thick, dashed, ->, >=stealth] (S2.south east) -- (C2.south west) node [midway, below] {result : \{...\}, id : 0 };
		
		\node[IsActive] (S3) at (0, -6) {};
		\node[IsActive] (C3) at (10, -6) {};
		\draw[thick, ->] (C3.north west) -- (S3.north east) node [midway, above] { method : loadScene, id : 1};
		\draw[thick, dashed, ->, >=stealth] (S3.south east) -- (C3.south west) node [midway, below] {result : \{...\}, id : 1 };
		
		\node[IsActive] (S4) at (0, -8) {};
		\node[IsActive] (C4) at (10, -8) {};
		\draw[thick, ->] (C4.north west) -- (S4.north east) node [midway, above] { method : setConfig, id : 2};
		\draw[thick, dashed, ->, >=stealth] (S4.south east) -- (C4.south west) node [midway, below] {result : \{...\}, id : 2 };
		
		\node[IsActive] (S5) at (0, -10) {};
		\node[IsActive] (C5) at (10, -10) {};
		\draw[thick, ->] (C5.north west) -- (S5.north east) node [midway, above] { method : getFrame, id : 3};
		\draw[thick, dashed, ->, >=stealth] (S5.south east) -- (C5.south west) node [midway, below] {result : \{...\}, id : 3 };
		
		\node[IsActive] (S6) at (0, -12) {};
		\node[IsActive] (C6) at (10, -12) {};
		\draw[thick, ->] (C6.north west) -- (S6.north east) node [midway, above] {disconnect};
		\draw[thick, dashed, ->, >=stealth] (S6.south east) -- (C6.south west) node [midway, below] {disconnected};
		
		\node[IsActive, minimum height=10.5cm] at (10, -7) {};
	\end{tikzpicture}
	\centering
	\caption{Das Sequenzdiagramm zeigt eine Beispielkommunikation, um ein Bild vom Server anzufordern.}
	\label{fig:Squenzdiagram}
\end{figure}

Kann sich der Client erfolgreich mit dem Server verbinden, fragt er die \textit{Playlist} ab.
Diese liefert dem Client alle Informationen über die zur Verfügung stehenden Szenen.
Sie enthält für jeden Frame einer Szene, dessen Kamerainformationen.
Nachdem der Client alle Szenen kennt, kann er den Server mitteilen, welche dieser laden soll.
Anschließend wird mit der Methode \textit{setConfig} eine gewählte Parameterkonfiguration gesetzt.
Mit Hilfe der \textit{Playlist}, kann ein beliebiger Frame der geladenen Szene, angefordert werden.
Wird der Frame empfangen, kann dieser vom Client anschließend extrapoliert werden.
Neben den Vorgestellten, stehen zusätzliche Methoden, zum Starten einer Messung beziehungsweise zum 
Speichern eines Bildes durch den Server zur Verfügung.

\section{Details zur Implementierung der Algorithmen}

In diesem Abschnitt werden Details zur Implementierung, der vorgestellten Algorithmen
genauer betrachtet.
Begonnen wird mit den Farbbildern.
Um eine verlustbehaftete Komprimierung ermöglichen zu können,
kommt das JPEG-Format zum Einsatz.  
Anschließend müssen die Bildinformationen mit Base64 kodiert werden, 
damit diese als String in ein JSON-Objekt integriert werden können.

\subsection{Vollvernetzung}

Im Fall der Vollvernetzung, wird neben dem Farbbild auch das Tiefenbild mit Base64 kodiert
und als String in ein JSON-Objekt eingebettet.
Im Gegensatz zu den Farbbildern, werden die Tiefenbilder verlustfrei als PNG komprimiert.

Die Dekodierung von Farb- und Tiefenbilder kann mit Hilfe des Bildcontainers nativ durch
vom Browser durchgeführt werden.
Im Bezug auf das Tiefenbild ergibt sich ein Problem.
Dieser Bildcontainer erlaubt für jeden Farbkanal ausschließlich eine Farbtiefe von 8 Bit.
Damit ein Shaderprogramm trotzdem auf 16 Bit Informationen aus einer Textur zurückgreifen 
kann, muss der 16 Bit Wert auf zwei Farbkanäle aufgeteilt werden und die Rekonstruktion
erfolgt im Shader.
Diese Aufteilung findet auf dem Server statt, bevor das Bild mit Base64 kodiert wird.
Auf den roten-Farbkanal entfallen die ersten 8 Bit und 
die zweiten 8 Bit, der 16 Bit Zahl werden auf den grünen Farbkanal ausgelagert.
Die Abbildung \ref{fig:use2channels} verdeutlicht die Aufteilung.

\begin{figure}[h]
	\begin{tikzpicture}
		\node[draw=none, fill=red!10, minimum width=8cm, minimum height=1cm] (B) at (-3.5,-1) {$d_{low}$};
		\node[draw=none, fill=green!10, minimum width=8cm, minimum height=1cm] (C) at (4.5,-1) {$d_{up}$};
			
		\foreach \x in {0,1,...,15}
			\draw (\x cm -7.5 cm, 0.5cm) -- (\x cm -7.5 cm,-0.5cm) node[anchor=south west] {$\x$};
		
		\draw (-7.5, -1.5) -- (-7.5, 0.5) -- (8.5, 0.5) -- (8.5, -1.5);
		\draw (-7.5, -0.5) -- (8.5, -0.5);
		\draw (-7.5, -1.5) -- (8.5, -1.5);
		\draw (0.5, -1.5) -- (0.5, -0.5);
	\end{tikzpicture}
	\centering
	\caption{Hier wird die Aufteilung einer 16 Bit Zahl auf die Farbkanäle, links rot und rechts grün, visuell verdeutlicht. Das Schlüsselwort $d_{up}$ bezeichnet die ersten 8 Bit und $d_{low}$ die zweiten 8 Bit.}
	\label{fig:use2channels}
\end{figure}

Um aus $d_{up}$ und $d_{low}$ die 16 Bit $d$ Zahl zu erhalten, genügt es den Wert von $d_{up}$
zuerst mit 255 zu multiplizieren und den Wert von $d_{low}$ zu addieren,
wie in der Gleichung \ref{eq:reconstruct1} beschrieben.

\begin{equation}
	d = d_{low} + d_{up} \cdot 256.
	\label{eq:reconstruct1}
\end{equation}

Die rekonstruierte Zahl $d$ aus der Gleichung \ref{eq:reconstruct1} liegt im Ganzzahligem Intervall $[0,65535]$.
Beim Zugriff auf die Farbwerte einer Textur im Shader, werden die jedoch normiert.
Das bedeutet, im Fall eines 8 Bit Farbkanals, wird jeder Wert durch den Maximalwert 255 geteilt.
Auf diese weise werden die Werte eines Pixels in das Intervall $[0, 1]$ überführt.
Um eine 16 Bit Zahl in dieses Intervall zu überführen, muss sie durch den Wert $65535$ geteilt werden.
Aus diesem Zusammenhang ergibt sich die folgende Gleichung zur Rekonstruktion der Zahl $d$:

\begin{equation}
	d = \frac{255 \cdot \frac{d_{low}}{255} + \frac{d_{up}}{255} \cdot 255 \cdot 265}{2^{16} -1}.
	\label{eq:reconstruct2}
\end{equation}

Die Zahl $65535$ lässt sich in das Produkt $65535 = 255 \cdot 257$ umschreiben
und dadurch Gleichung \ref{eq:reconstruct2} kann weiter vereinfacht werden:

\begin{align}
	d &= \frac{ \cancel{255} \cdot \left( \frac{d_{low}}{255} + \frac{d_{up}}{255} \cdot 265 \right)}{\cancel{255} \cdot 257} \\
	&= \frac{d_{low}}{255} \cdot \frac{1}{257} + \frac{d_{up}}{255} \cdot \frac{256}{257}
		\label{eq:reconstruct3}
\end{align}

Im Shader kann die 16 Bit zahl deshalb einfach entsprechend der Gleichung \ref{eq:reconstruct3} rekonstruieren.
Der Farbwert des roten Farbkanals wird mit (1/257) multipliziert und der des grünen mit (256/257).
Im Anschluss daran werden die beiden Werte aufsummiert und der Wert der 16 Bit Zahl steht im Shader zur Verfügung.

Im Fall der Vollvernetzung, werden alle Dreiecke, die zum Hintergrund gehören transparent gezeichnet.
Zusätzlich wird im Vertex-Shader, der Gradient des bearbeiteten Vertice berechnet.
Der x- und y-Anteil des Gradienten, wird mit dem Schwellwert $g$ verglichen.
Ist einer dieser beiden Gradientkomponenten größer als der Schwellwert $g$, 
wird der Alphakanal an dieser Stelle ebenfalls auf 0 gesetzt.

Damit verdeckte Fragmente durch die transparenten sichtbar werden,
kommt ein 3 und ein 5 Pass \textit{depth peeling}-Verfahren zum Einsatz.

\subsection{Delaunay-Triangulierung}

Beim \textit{Quadtree}, wird der Bildbereich sukzessiv in vier gleichgroße Regionen aufgeteilt,
deren Eckpunkte in der Punktmenge $P$ landen können.
Die Abbildung \ref{fig:qt_points} veranschaulicht die Aufteilung.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\draw (0,0) -- (8,0) -- (8,6) -- (0,6) -- cycle;
		\draw (4,0) -- (4,6);
		\draw (0,3) -- (8,3);
		\node at (2, 4.5) {$R_1$};
		\node at (6, 4.5) {$R_2$};
		\node at (2, 1.5) {$R_3$};
		\node at (6, 1.5) {$R_4$};
		\node[circle, minimum width=1em,fill=OliveGreen] at (4,0) {};
		\node[circle, minimum width=1em,fill=OliveGreen] at (8,3) {};
		\node[circle, minimum width=1em,fill=OliveGreen] at (0,3) {};
		\node[circle, minimum width=1em,fill=OliveGreen] at (4,6) {};
		\node[circle, minimum width=1em,fill=OliveGreen] at (4,3) {};
	\end{tikzpicture}
	\caption{Unterteilung eines Rechtecks, in vier Teilflächen. 
			 An den grünen markierten Positionen, gibt es mehrere Möglichkeiten, wie die
			 Eckpunkte der betreffenden Rechtecke gesetzt werden können.}
	\label{fig:qt_points}
\end{figure}

Dabei gibt es mehrere Möglichkeiten, wie die Eckpunkte der Teilfenster gewählt werden können.
Einerseits können die Flächen, exakt gleich groß gewählt werden. 
Mit dem Effekt, das viele kleine Dreiecke dadurch entstehen, 
dass die grün markierten Punkte sich aus mindestens zwei Eckpunkten zusammensetzten, 
die sich jeweils nur um eine Pixeleinheit voneinander unterscheiden. 

Die zweite Möglichkeit besteht darin, für derartige Eckpunkte dieselbe Koordinate
zu wählen. 
Auf diese Weise lässt sich die Anzahl der in der Punktmenge $P$ enthaltenen Punkte,
bei gleichbleibender Bildqualität senken.
In dieser Arbeit wird die zweite Variante verwendet.

Bei der Erzeugung der Gradientenbilder, mit dem Sobel-operator, entsteht ein Rand
mit der Breite von einem Pixel.
Dieser wird auch bei der Binärisierung von dem Merkmalsbild $\sigma$ ausgelassen.

Um die Netzoptimierung durchführen zu können, müssen die Punkte $p_1', p_1'', p_2', _2''$,
sowie $p_3'$ und $p_3''$ bestimmt werden.
Diese Aufgabe wird mit Hilfe einer Linienrasterisierung gelöst.
Dabei wird nicht zwischen den Pixeln interpoliert.

\chapter{Ergebnisse}

Zu Beginn dieses Kapitels wird beschrieben, wie die Ergebnisse erhoben werden.
Anschließend werden die Parameterkonfigurationen und deren Resultate vorgestellt.
Dabei auftretende Besonderheiten werden kenntlich gemacht.

Die Vollvernetzung und die beiden Varianten der Delaunay-Triangulierung werden,
mit den beiden \textit{Ground-Truth}-Datensätzen, \textit{TestSpheres} und \textit{CoolRandom}, evaluiert.
Der erste Frame einer Szene dient als Referenz für die Extrapolation.
Aus dessen Tiefenbild wird mit dem gewählten Alogithmus ein Dreiecksnetz erzeugt.
Zusammen mit dem dazugehörigen Farbbild wird es zum Client gesendet.
Anschließend wird Dreiecksnetz, texturiert mit dem Farbbild, 
aus allen Kameraperspektiven der Szene gezeichnet und
die dabei entstandenen Bilder werden zurück zum Server gesendet.
Die Qualität aller extrapolierten Bilder wird durch den PSNR und den SSIM bestimmt.
Zusätzlich wird gemessen wie lange der Server für die Kodierung benötigt
und wie lange der Client für die Extrapolation eines Bildes braucht.

Für die Vollvernetzung wurde das Tiefenbild mit 8 und 16 Bit kodiert. 
Es wurde ein 3 Pass und ein 5 Pass Verfahren verwendet, 
um die Transparenz mit \textit{depth peeling} zu realisieren.
Und schließlich wurden die Schwellwerte $g \in \{1, 0.9, 0.8\}$ für den
Vergleich mit dem Gradienten getestet.
Die besten Ergebnisse werden mit 16 Bit, $g = 1$ und dem 5 Pass Verfahren erzielt.
Diese Konfiguration dient als Basis für den Vergleich mit den Delaunay-Verfahren.

Im Fall der Delaunay-Triangulation, wird zwischen den beiden Punktgenerierungsverfahren
\textit{Quadtree} und \textit{Floyd-Steinberg} unterschieden.
Für den \textit{Quadtree}-Ansatz werden generell alle Hintergrundpixel verworfen.
Die Bäume werden mit den maximalen Baumtiefen $t_{max} \in \{10, 9, 8\}$ erzeugt.
Für jede Baumtiefe $t_{max}$ wurden die Schwellwertkonfigurationen
$l \in \{0.1,0.2, ..., 1.0\}$ und $i \in \{0.1, ..., l\}$ gemessen.
Für alle $l > 0.6$ und $i = 0.6$, wurden zusätzlich die Netzverfeinerung durchgeführt. 
Mit den Schwellwerten $\alpha \in \{0.1, 1, 10, 100, 1000\}$ und $\beta \in \{0.1, 0.2, ..., 1.0\}$.
Die Erzeugung der Punktemenge erhoben mit dem \textit{Floyd-Steinberg}-Fehlerdiffusionsverfahren,
wird mit den Parametern $\delta, \gamma \in \{0.1,0.2, ..., 1.0 \}$ evaluiert.
Die folgenden Diagramme zeigen ausgewählte Beispiele von den erhobenen Daten.
Dabei wird mit den besten Ergebnissen begonnen:

\begin{figure}[H]
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
			 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
			 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
			 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512T0.3G0.3.csv};	
	
		\end{axis}
		%legend
		\begin{scope}[shift={(3,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{Full, 16Bit, 5Pass, G1.0};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{QT, $t_{max} = 10$, $i,l = 0$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{FS, $\delta, \gamma = 0.3$};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512T0.3G0.3.csv};	
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512T0.3G0.3.csv};	
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512T0.3G0.3.csv};	
		\end{axis}
	\end{tikzpicture}} 
	\caption{Die Diagramme a und b zeigen die Ergebnisse des Datensatzes \textit{TestSpheres},
			 während c und d die Resultate des Datensatzes \textit{CoolRandom} abtragen.
			 Dabei zeigen a und c die Ergebnisse des SSIM, während in b und d
			 die Ergebnisse des PSNR gezeigt werden.}
	\label{fig:Daten_best_cases}
\end{figure}

Die Abbildung \ref{fig:Daten_best_cases} zeigt die besten Resultate, der Vollvernetzung,
vom \textit{Quadtree}, sowie von der \textit{FloydSteinberg} Variante der Delaunay-Triangulierung.
Für beide Szenen gemessen mit dem SSIM liefert die Vollvernetzung insgesamt die besten Ergebnisse,
dicht gefolgt vom \textit{Quadtree}-Ansatz und die schlechtesten Ergebnisse liefert der \textit{FloydSteinberg} Ansatz.
Interessant ist, dass die Güte der Ergebnisse von dem \textit{CoolRandom}-Datensatz,
gemessen mit dem PSNR, schon bei den ersten extrapolierten Frames unter 25 $dB$ liegt.
Außerdem fällt beim PSNR auf, dass die Werte, ab einem Winkel von 70 Grad wieder leicht ansteigen.

\begin{figure}[H]
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,15,...,20},
			 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
			 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
			 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512T0.3G0.3.csv};	
	
		\end{axis}
		%legend
		\begin{scope}[shift={(3,5)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{Full, 16Bit, 5Pass, G1.0};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{QT, $t_{max} = 10$, $i,l = 0$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{FS, $\delta, \gamma = 0.3$};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, 
		 xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512T0.3G0.3.csv};	
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, 
		 xmin=0, xmax=10,
		 %xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512T0.3G0.3.csv};	
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512Fd1651.0.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512T0.3G0.3.csv};	
		\end{axis}
	\end{tikzpicture}} 
	\caption{Darstellung der Graphen aus der Abbildung \ref{fig:Daten_best_cases} im Winkelintervall von 0 bis 10 Grad.}
	\label{fig:Daten_best_cases_zoom}
\end{figure}

Die Abbildung \ref{fig:Daten_best_cases_zoom} zeigt die gleichen Parameterkonfigurationen,
wie die Abbildung \ref{fig:Daten_best_cases},
dieses mal jedoch beschränkt auf die Kamerawinkelunterschiede von 0 bis 10 Grad.
Hier zeigt sich sowohl mit dem SSIM, als auch beim PSNR, ein signifikanter unterschied
zwischen dem FloydSteinberg-Ansatz und den anderen beiden Methoden. 
Der \textit{Quadtree}-Ansatz ist in den ersten Frames sogar besser als die
Vollvernetzung.

\begin{figure}[H]
	\subfigure[]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
			 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.1I0.1pre.csv};
	
		\end{axis}
		%legend
		\begin{scope}[shift={(3,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{Quadtree, $t_{max} = 10$};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{Quadtree, $t_{max} = 9$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{Quadtree, $t_{max} = 8$};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D8L0.1I0.1pre.csv};
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.1I0.1pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D8L0.1I0.1pre.csv};
		\end{axis}
	\end{tikzpicture}} 
	\caption{Die Diagramme a und b zeigen die Ergebnisse des Datensatzes \textit{TestSpheres},
				 während c und d die Resultate des Datensatzes \textit{CoolRandom} abtragen.
				 Dabei zeigen a und c die Ergebnisse des SSIM, während in b und d
				 die Ergebnisse des PSNR gezeigt werden.}
	\label{fig:Daten_QT_1098}
\end{figure}

Die Abbildung \ref{fig:Daten_QT_1098} zeigt die Ergebnisse \textit{Quadtrees}-Ansatzes, 
mit unterschiedlichen maximalen Baumtiefen.
Dabei zeigt sich das der unterschied in der Szene \textit{TestSpheres} nur gering ist.
Anders fallen die Ergebnisse für die \textit{CoolRandom} Szene aus.
Hier zeigt sich ein deutlicher Unterschied zwischen drei Varianten,
insbesondere im Intervall von 5 bis 50 Grad.
Die Gütewerte für die Baumtiefe $t_{max} = 8$, liegen dabei deutlich unterhalb der anderen.
Im Fall der \textit{CoolRandom} Szene zeigt sich bei der Messung mit dem PSNR eine erneute 
Verbesserung bei Winkelunterschieden, die größer als 70 Grad sind. 

% % % % % % % % % % % % % % % % % % % % % % % % % % %
\begin{figure}[H]
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
			 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.1I0.1pre.csv};
	
		\end{axis}
		%legend
		\begin{scope}[shift={(5,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{$t_{max} = 10$};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{$t_{max} = 9$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{$t_{max} = 8$};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D8L0.1I0.1pre.csv};
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.1I0.1pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, 
		xmin=0, xmax=10,
		%xtick={0,5,10,20,...,90},
		every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.1I0.1pre.csv};	
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D9L0.1I0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D8L0.1I0.1pre.csv};
		\end{axis}
	\end{tikzpicture}} 
	\caption{Die Diagramme a und b zeigen die Ergebnisse des Datensatzes \textit{TestSpheres},
				 während c und d die Resultate des Datensatzes \textit{CoolRandom} abtragen.
				 Dabei zeigen a und c die Ergebnisse des SSIM, während in b und d
				 die Ergebnisse des PSNR gezeigt werden.}
	\label{fig:Daten_QT_1098_zoom}
\end{figure}

Die Diagramme aus der Abbildung \ref{fig:Daten_QT_1098_zoom},
zeigen die gleichen Graphen, wie die Abbildung \ref{fig:Daten_QT_1098},
allerdings im Intervall von 0 bis 10 Grad.
Der Unterschied der Güte zwischen den Parameterkonfigurationen, wird hierbei noch deutlicher.

Um die Schwellwerte $l$ und $i$ zu untersuchen, 
wird der SSIM von einem konstanten Kamerawinkelunterschied betrachtet.
Zu diesem Zweck wird der 20 Grad Winkel gewählt, weil wie in der Abbildung \ref{fig:Daten_QT_1098}
zu erkennen, eine höhere Streuung der Werte zu erwarten ist.
Dadurch werden die Qualitätsunterschiede zwischen den Parameterkonfigurationen besonders deutlich.

\begin{figure}
	\centering
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.85, point meta max=0.95,
		 			 colormap={greenyellow}{
						rgb255(0cm)	 =(255,128,0)
						rgb255(0.5cm) =(255,255,0)
						rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
			   			 	rgb255(0cm)	 =(240,240,240)
			   			 	rgb255(0.5cm) =(0,128,128) 
			   			 	rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10_cost.csv};      
		\end{axis}
	\end{tikzpicture}}

	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.85, point meta max=0.95,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(255,128,0)
		   			 	rgb255(0.5cm) =(255,255,0)
		   			 	rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
			   			 	rgb255(0cm)	 =(240,240,240)
			   			 	rgb255(0.5cm) =(0,128,128) 
			   			 	rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9_cost.csv};      
		\end{axis}
	\end{tikzpicture}}

	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.85, point meta max=0.95,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(255,128,0)
		   			 	rgb255(0.5cm) =(255,255,0)
		   			 	rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
			   			 	rgb255(0cm)	 =(240,240,240)
			   			 	rgb255(0.5cm) =(0,128,128) 
			   			 	rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{Ergebnisse des \textit{Quadtree}-Ansatz mit \textit{TestSpheres}Datensatz,
			 bei einem konstanten Kamerawinkelunterschied von 20 Grad.
			 Dabei liegt die maximale Baumtiefe in a,b bei 10,
			 in c,d bei 9 und in e,f bei 8. Die Diagramme auf der linken Seite
			 zeigen die Güte mit Hilfe des SSIM Wertes. 
			 Auf der rechten Seite wird die Konstruktionszeit des Netzes abgetragen, die der Server benötigt.}
	\label{fig:qt_TestSpheres_gc}
\end{figure}

In der Abbildung \ref{fig:qt_TestSpheres_gc} sind die Güte und die Netzkonstruktionszeit
des \textit{TestSpheres}-Datensatzes abgebildet.
Es ist zu erkennen, dass die Güte mit der maximalen Baumtiefe $t_{max}$ abnimmt.
Der Güteunterschied zwischen den einzelnen Konfigurationen von $l$ und $i$,
ist bei konstanter Baumtiefe allerdings gering.
Anders sieht es mit der Konstruktionszeit aus, hier zeigt sich deutliche Unterschiede.
Bei $t_{max} = 10$ und für $i = 0$ ist die Konstruktionszeit für alle $l$ größer
als 120 ms. 
Für die maximale Baumtiefe $t_{max} = 9$ überschreitet die Konfiguration $l,i = 0$ die Marke
von 120 ms.

\begin{figure}[H]
	\centering
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.7, point meta max=0.9,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture}[scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
							rgb255(0cm)	 =(240,240,240)
							rgb255(0.5cm) =(0,128,128) 
							rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.7, point meta max=0.9,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
							rgb255(0cm)	 =(240,240,240)
							rgb255(0.5cm) =(0,128,128) 
							rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9_cost.csv};      
		\end{axis}
	\end{tikzpicture}}

	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=0.7, point meta max=0.9,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 			 xlabel=$i$,
			 			 ylabel=$l$,
			 			 ylabel style={rotate=-90},
			 			 point meta min=20.0,
			 			 point meta max=120.0,
			 			 colormap={greenyellow}{
							rgb255(0cm)	 =(240,240,240)
							rgb255(0.5cm) =(0,128,128) 
							rgb255(1cm) =(0,0,80)
			 			 }, 
			 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 			 xtick={0.0,0.1,...,1.1},
			     		 ytick={0.0,0.1,...,1.1},
			     		 xmajorgrids=true, ymajorgrids=true]
			 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{Ergebnisse des \textit{Quadtree}-Ansatz mit \textit{CoolRandom},
			 bei einem konstanten Kamerawinkelunterschied von 20 Grad.
			 Dabei liegt die maximale Baumtiefe in a,b bei 10,
			 in c,d bei 9 und in e,f bei 8. Die Diagramme auf der linken Seite
			 zeigen die Güte mit Hilfe des SSIM Wertes. 
			 Auf der rechten Seite wird die Gesamtkonstruktionszeit des Netzes abgetragen.}
	\label{fig:qt_CoolRandom_gc}
\end{figure}

Vergleichbar zur Abbildung \ref{fig:qt_TestSpheres_gc}, werden Güte und Konstruktionszeit,
in der Abbildung \ref{fig:qt_CoolRandom_gc} für den \textit{CoolRandom}-Datensatz dargestellt.
Die Güte variiert wesentlich stärker, als im \textit{TestSpheres}-Datensatz.
Zu erkennen ist eine Abnahme der Güte mit steigenden $l$ und $i$, wenn die maximale
Baumtiefe $t_{max} = 10$ beträgt.
Für die anderen beiden maximalen Baumtiefen $8$ und $9$, ist die Güte für alle $i$ und $l$
relativ konstant.
Auch bei dieser Szene zeigt sich das bei $t_{max} = 10$ die Konstruktionszeiten am größten sind.
Unabhängig von $l$ und $i$ überschreiten alle die Marke von 120 ms.
Bei der maximalen Baumtiefe $t_{max} = 9$ zeigt sich eine deutliche Veränderung 
der Konstruktionszeiten bezüglich $l$ und $i$.
Je kleiner $l$ und $i$ umso größer ist die Berechnungszeit.
Anders sieht es bei $t_{max} = 8$ aus. In diesem Fall sind alle Berechnungszeiten
unterhalb von 40 ms.

\begin{figure}[H]
	\centering
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=60000, point meta max=120000,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 = (200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
		 			 }, 
		 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=60000, point meta max=120000,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
		 			 }, 
		 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=10000, point meta max=40000,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
		 			 }, 
		 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$i$,
	 			 ylabel=$l$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=10000, point meta max=40000,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
	 			 }, 
	 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}

	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$i$,
	 			 ylabel=$l$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=5000, point meta max=10000,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
	 			 }, 
	 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse, scaled y ticks=base 10:-3}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$i$,
		 			 ylabel=$l$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=5000, point meta max=10000,
		 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse, scaled y ticks=base 10:-3}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{Die Diagramme zeigen für den \textit{Quadtree}-Ansatz,
			 bei einem konstanten Kamerawinkelunterschied von 20 Grad die Anzahl der Dreiecke
			 in Abhängigkeit der Parameter $l,i$ und $t_{max}$.
			 Dabei liegt die maximale Baumtiefe in a,b bei 10,
			 in c,d bei 9 und in e,f bei 8. 
			 Die Diagramme auf der linken Seite zeigen die Anzahl der Dreiecke von der \textit{TestSpheres} Szene. 
			 Auf der rechten Seite wird die Anzahl der Dreiecke von \textit{CoolRandom} dargestellt.}
	\label{fig:Daten_QT_1098_Tri}
\end{figure}

In der Abbildung \ref{fig:Daten_QT_1098_Tri} ist die Anzahl der Dreiecke,
in Abhängigkeit von $l$ und $i$, sowie der maximalen Baumtiefe $t_{max}$ abgebildet.
Wird der Datensatz \textit{TestSpheres} betrachtet,
zeigt sich für alle $t_{max}$, dass bei der Parameterkonfiguration $l = 0, i = 0$
wesentlich mehr Dreiecke erzeugt werden als bei allen anderen Konfigurationen von $l$ und $i$.
Für den Datensatz \textit{CoolRandom} sieht es etwas anders aus,
hier zeigt sich, dass die Anzahl der Dreiecke sinkt, wenn $l$ und $i$ größer werden,
vor allem wenn $t_{max} = 10$ ist.

\begin{figure}[H]
	\centering
	\subfigure[]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\gamma$,
	 			 ylabel=$\delta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=0.7, point meta max=0.9,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
	 			 }, 
	 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7floydSteinberg.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\gamma$,
	 			 ylabel=$\delta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=0.7, point meta max=0.9,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
	 			 }, 
	 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6floydSteinberg.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\gamma$,
	 			 ylabel=$\delta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=20.0,
	 			 point meta max=120.0,
	 			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
	 			 }, 
	 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
	 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7floydSteinberg_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
		 			 xlabel=$\gamma$,
 	 			 	 ylabel=$\delta$,
		 			 ylabel style={rotate=-90},
		 			 point meta min=20.0,
		 			 point meta max=120.0,
		 			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
		 			 }, 
		 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
		 			 xtick={0.0,0.1,...,1.1},
		     		 ytick={0.0,0.1,...,1.1},
		     		 xmajorgrids=true, ymajorgrids=true]
		 \addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6floydSteinberg_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\gamma$,
			 ylabel=$\delta$,
 			 ylabel style={rotate=-90},
 			 point meta min=100000, point meta max=500000,
 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
 			 }, 
 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
 			 xtick={0.0,0.1,...,1.1},
     		 ytick={0.0,0.1,...,1.1},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7floydSteinberg_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}[scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\gamma$,
	 			 ylabel=$\delta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=100000, point meta max=500000,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(200,200,200)
		   			% 	rgb255(0.5cm) =(255,255,255) 
		   			 	rgb255(1cm) =(95,25,135)
	 			 }, 
	 			 colorbar, colorbar style={xlabel=\#Dreiecke, y dir=reverse}, enlargelimits=true, 
	 			 xtick={0.0,0.1,...,1.1},
	     		 ytick={0.0,0.1,...,1.1},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6floydSteinberg_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{Die Diagramme a, b stellen die Ergebnisse von dem \textit{CoolRandom} Datensatz
			 und c, d die des \textit{TestSpheres} Datensatzes erhoben mit FloydSteinberg Ansatz dar.
			 Die Diagramme auf der linken Seite zeigen die Güte mit Hilfe des SSIM und die
			 Diagramme auf der rechte Seite bilden die Gesamtkompressionszeit des Netzes ab.}
	\label{fig:data_floydSteinberg}
\end{figure}

Analog zu den Schwellwerten der \textit{Quadtree}-Methode, werden die Parameter $\delta$ und $\gamma$,
vom \textit{FloydSteinberg}-Verfahren in der Abbildung \ref{fig:data_floydSteinberg} dargestellt.
Dabei sind die Ergebnisse, für die Szene \textit{TestSpheres} hinsichtlich der Güte, für alle Konfigurationen größer als $0.9$.
Bei der Berechnungszeit zeigt sich, dass erst ab den Konfigurationen $\delta > 0.5$ und $\gamma > 0.5$,
die Konstruktionszeiten kleiner als 100 ms werden.
Die Anzahl der Dreiecke ist bei den Konfigurationen $\gamma = 0$ oder für $\delta = 0$ am Höchsten.
Anders sieht es bei dem Datensatz \textit{CoolRandom} aus.
Die Gütewerte liegen alle unterhalb von $0.8$,
dabei zeigt sich eine zunehmende Verschlechterung für Konfigurationen 
mit $\delta > 0.6$ und $\gamma > 0.6$.
Die Konstruktionszeiten des Netzes sind für alle Parameterkonfigurationen größer als 120 ms,
bis auf die Konfiguration $\gamma = 1$ und $\delta = 0.9$.
Mit der Anzahl der Dreiecke verhält es sich ähnlich, wie für die Szene \textit{TestSpheres}.

Der Netzoptimierungsschritt wird ausschließlich mit dem \textit{Quadtree}-Ansatz untersucht,
da dessen Ergebnisse weitaus besser sind, als die der FloydSteinberg-Methode.
Um die Parameter $\alpha$ und $\beta$ auszuwerten, 
werden $l$ und $i$ konstant auf einen Wert fixiert. 
Zu diesem Zweck wurde $l = 0.7$ und $i = 0.6$ gewählt. 

\begin{figure}[H]
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
			 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
			 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6pre.csv};
	%	\addlegendentry{Case 1}	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
		%legend
		\begin{scope}[shift={(3,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{$\alpha = 10$, $\beta = 0.2$};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{$\alpha = 10$, $\beta = 0.1$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{ohne Nachbearbeitung};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D10L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{	
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\caption{Es wird der Datensatz \textit{TestSpheres} betrachtet.
			 Die Diagramme zeigen die Güteentwicklung, in Abhängigkeit des Parameters j.
			 Dabei liegt die maximale Baumtiefe in a,b bei 10, in c,d bei 9 und in e,f bei 8.}
	\label{fig:data_refine1}
\end{figure}

\begin{figure}[H]
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
			 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
			 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
		%legend
		\begin{scope}[shift={(3,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{$\alpha = 10$, $\beta = 0.2$};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{$\alpha = 10$, $\beta = 0.1$};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{ohne Nachbearbeitung};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D10L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{	
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in dB}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	 
		\addplot[red, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6pre.csv};	 
		\addplot[blue, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6A10.0J0.1pre.csv};
		\addplot[green, only marks, mark=x] table [x=a, y=p, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6A10.0J0.2pre.csv};
		\end{axis}
	\end{tikzpicture}}
	\caption{Es wird der Datensatz \textit{CoolRandom} betrachtet.
			 Die Diagramme zeigen die Güteentwicklung, in Abhängigkeit des Parameters j.
			 Dabei liegt die maximale Baumtiefe in a,b bei 10, in c,d bei 9 und in e,f bei 8.}
	\label{fig:data_refine10}
\end{figure}

Die Diagramme aus der Abbildungen \ref{fig:data_refine1} und \ref{fig:data_refine10}
stellen dar, wie sich der Netzoptimierungsschritt auf die Dreiecksnetze hinsichtlich
der Güte auswirkt.
Zum Vergleich dient das nicht nachbearbeitete Netz.
Dabei wird $\alpha = 10$ gesetzt und $\beta \in \{0.1, 0.2\}$ gewählt.

Deutlich zu sehen ist, dass bei kleinen Winkeln die nachbearbeiteten Netze 
schlechter abschneiden, als die nicht optimierten.
In allen Fällen existiert ein Kipppunkt,
ab dem die optimierten Netze hinsichtlich der Güte bessere Ergebnisse liefern.
Bei kleineren $t_{max}$ wird dieser Kipppunkt schneller erreicht.
Beim PSNR zeigt sich dieser Kipppunkt erst bei größeren Winkeln.
Außerdem steigt beim PSNR die Güte oberhalb von 60 Grad wieder an.

Die Parameter des Netzoptimierungsschrittes werden ähnlich ausgewertet,
wie zuvor $l$ und $i$.
Zu diesen Zweck werden $l = 0.7$ und $i = 0.6$ gesetzt.
Getestet werden die Parameter $\alpha \in \{0.1, 1, 10, 100, 1000\}$ und $\beta \in \{0.1, 0.2, ..., 1.0\}$

\begin{figure}
	\centering
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=0.89, point meta max=0.91,
 			 colormap={greenyellow}{
 		   			 	rgb255(0cm)	 =(255,128,0)
 		   			 	rgb255(0.5cm) =(255,255,0)
 		   			 	rgb255(1cm) =(0,200,0)
			 }, 
 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
 			 xmode=log,
 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
     		 ytick={0.1,0.2,...,1.0},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 xlabel=$\alpha$,
			 ylabel=$\beta$,
			 ylabel style={rotate=-90},
			 point meta min=20.0,
			 point meta max=120.0,
			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
			 }, 
			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 xmode=log,
		 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
    		 ytick={0.0,0.1,...,1.1},
    		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=0.89, point meta max=0.91,
 			 colormap={greenyellow}{
 		   			 	rgb255(0cm)	 =(255,128,0)
 		   			 	rgb255(0.5cm) =(255,255,0)
 		   			 	rgb255(1cm) =(0,200,0)
			 }, 
 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
 			 xmode=log,
 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
     		 ytick={0.1,0.2,...,1.0},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 xlabel=$\alpha$,
			 ylabel=$\beta$,
			 ylabel style={rotate=-90},
			 point meta min=20.0,
			 point meta max=120.0,
			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
			 }, 
			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 xmode=log,
		 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
    		 ytick={0.0,0.1,...,1.1},
    		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\alpha$,
	 			 ylabel=$\beta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=0.89, point meta max=0.91,
				colormap={greenyellow}{
				 	rgb255(0cm)	 =(255,128,0)
				 	rgb255(0.5cm) =(255,255,0)
				 	rgb255(1cm) =(0,200,0)
				}, 
	 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
	 			 xmode=log,
	 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
	     		 ytick={0.1,0.2,...,1.0},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=20.0,
 			 point meta max=120.0,
 			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
 			 }, 
 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
 			 xmode=log,
			 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
     		 ytick={0.0,0.1,...,1.1},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{}
	\label{fig:nnt}
\end{figure}

In der Abbildung \ref{fig:nnt}, wird der Datensatz \textit{TestSpheres} betrachtet,es zeigt sich für $t_{max} = 10$,
das die Güte ab $\alpha > 1$ größer als $0.9$ ist.
Im Vergleich dazu ist eine Verbesserung der Güte bei $t_{max} < 10$ auch bei $\alpha < 10$
zu erkennen.
Es lässt sich feststellen, dass für alle $t_{max}$ die besten Konstruktionszeiten für $\beta < 0.3$
erreicht werden.

\begin{figure}
	\centering
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=0.75, point meta max=0.82,
 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
 			 }, 
 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
 			 xmode=log,
 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
     		 ytick={0.1,0.2,...,1.0},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 xlabel=$\alpha$,
			 ylabel=$\beta$,
			 ylabel style={rotate=-90},
			 point meta min=20.0,
			 point meta max=120.0,
			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
			 }, 
			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 xmode=log,
		 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
    		 ytick={0.0,0.1,...,1.1},
    		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=0.75, point meta max=0.82,
 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
 			 }, 
 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
 			 xmode=log,
 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
     		 ytick={0.1,0.2,...,1.0},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
			 xlabel=$\alpha$,
			 ylabel=$\beta$,
			 ylabel style={rotate=-90},
			 point meta min=20.0,
			 point meta max=120.0,
			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
			 }, 
			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
			 xmode=log,
		 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
    		 ytick={0.0,0.1,...,1.1},
    		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.79]
		\begin{axis}[view={0}{90}, grid=major,
	 			 xlabel=$\alpha$,
	 			 ylabel=$\beta$,
	 			 ylabel style={rotate=-90},
	 			 point meta min=0.75, point meta max=0.82,
	 			 colormap={greenyellow}{
		   			 	rgb255(0cm)	 =(128,0,0)
		   			 	rgb255(0.5cm) =(255,255,0) 
		   			 	rgb255(1cm) =(0,200,0)
	 			 }, 
	 			 colorbar, colorbar style={xlabel={SSIM}}, enlargelimits=true,
	 			 xmode=log,
	 			 log ticks with fixed point,
	 			% xtick={0.1,1.0,10,100,1000},
	     		 ytick={0.1,0.2,...,1.0},
	     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8_L0.7_I0.6.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
			\begin{axis}[view={0}{90}, grid=major,
 			 xlabel=$\alpha$,
 			 ylabel=$\beta$,
 			 ylabel style={rotate=-90},
 			 point meta min=20.0,
 			 point meta max=120.0,
 			 colormap={greenyellow}{
						rgb255(0cm)	 =(240,240,240)
						rgb255(0.5cm) =(0,128,128) 
						rgb255(1cm) =(0,0,80)
 			 }, 
 			 colorbar, colorbar style={xlabel={in ms}, y dir=reverse}, enlargelimits=true, 
 			 xmode=log,
			 log ticks with fixed point,
 			% xtick={0.0,0.1,...,1.1},
     		 ytick={0.0,0.1,...,1.1},
     		 xmajorgrids=true, ymajorgrids=true]
			\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8_L0.7_I0.6_cost.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{SSIM und Netzkonstruktionszeit, bei einem konstanten Winkelunterschied von 20 Grad.}
	\label{fig:nnc}
\end{figure}

In der Abbildung \ref{fig:nnc}, sind die Parameter für den Datensatz \textit{CoolRandom}
abgebildet.
Hinsichtlich der Güte lässt sich kein Unterschied im Bezug auf $\alpha$ erkennen.
Die besten Ergebnisse werden für $\beta < 0.3$ erreicht.
Mit steigenden $t_{max}$ steigt die Güte.
Die Konstruktionszeiten sind bei $t_{max} > 0.8$ für alle Parameterkonfigurationen größer als 120 ms.
Für $t_{max} = 8$ liegen alle unterhalb von 70 ms.

\begin{figure}
	\centering
	\subfigure[\textit{TestSpheres}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=20000, point meta max=30000,
		colormap={greenyellow}{
		 	rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
		 	rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse}, enlargelimits=true, 
		xmode=log,
			log ticks with fixed point,
			% xtick={0.0,0.1,...,1.1},
		 ytick={0.0,0.1,...,1.1},
		 xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D10_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 10$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=50000, point meta max=80000,
		colormap={greenyellow}{
		 	rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
		 	rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse}, enlargelimits=true, 
		xmode=log,
	 	log ticks with fixed point,
			% xtick={0.0,0.1,...,1.1},
		 ytick={0.0,0.1,...,1.1},
		 xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D10_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
		
	\subfigure[\textit{TestSpheres}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=10000, point meta max=20000,
		colormap={greenyellow}{
			rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
			rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse}, enlargelimits=true, 
		xmode=log,
		log ticks with fixed point,
		% xtick={0.0,0.1,...,1.1},
		ytick={0.0,0.1,...,1.1},
		xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D9_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 9$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=30000, point meta max=50000,
		colormap={greenyellow}{
		 	rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
		 	rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse}, enlargelimits=true, 
		xmode=log,
			log ticks with fixed point,
			% xtick={0.0,0.1,...,1.1},
		ytick={0.0,0.1,...,1.1},
		xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D9_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
				
	\subfigure[\textit{TestSpheres}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=5000, point meta max=10000,
		colormap={greenyellow}{
		 	rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
		 	rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse, scaled y ticks=base 10:-4}, enlargelimits=true, 
		xmode=log,
			log ticks with fixed point,
			% xtick={0.0,0.1,...,1.1},
		ytick={0.0,0.1,...,1.1},
		xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_7_D8_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}, $t_{max} = 8$]{
	\begin{tikzpicture} [scale=0.8]
		\begin{axis}[view={0}{90}, grid=major,
		xlabel=$\alpha$,
		ylabel=$\beta$,
		ylabel style={rotate=-90},
		point meta min=10000, point meta max=30000,
		colormap={greenyellow}{
		 	rgb255(0cm)	 =(200,200,200)
		% 	rgb255(0.5cm) =(255,255,255) 
		 	rgb255(1cm) =(95,25,135)
		}, 
		colorbar, colorbar style={xlabel={\#Dreiecke}, y dir=reverse}, enlargelimits=true, 
		xmode=log,
			log ticks with fixed point,
			% xtick={0.0,0.1,...,1.1},
		ytick={0.0,0.1,...,1.1},
		xmajorgrids=true, ymajorgrids=true]
		\addplot3[only marks, mark=square*, mark size=7, ycomb, scatter] file {div_s_6_D8_L0.7_I0.6_triangle.csv};      
		\end{axis}
	\end{tikzpicture}}
	\caption{}
	\label{fig:nnd}
\end{figure}

In der Abbildung \ref{fig:nnd}, wird die Anzahl der Dreiecke in Abhängigkeit von
$\alpha, \beta$ und $t_{max}$ dargestellt.
Zu erkennen ist für die Szene \textit{TestSpheres}, dass die Anzahl der Dreiecke
für die Konfigurationen $\alpha > 1$ am kleinsten ist.
In der Szene \textit{CoolRandom}, zeigt sich diese Tendenz sehr schwach.
Für beide Szenen fällt die Anzahl der Dreiecke mit $\beta$, jedoch nur sehr gering.


\begin{figure}
	\subfigure[\textit{TestSpheres}]{
	\begin{tikzpicture}
		\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]		
		\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D9L0.7I0.6pre.csv};
		\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6pre.csv};		 
		\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_7_512x512D8L0.7I0.6A10.0J0.2pre.csv};
	
		\end{axis}
		%legend
		\begin{scope}[shift={(2.5,4)}] 
		\draw (0,0) -- 
			plot[mark=*, mark options={fill=green}] (0,0) node[right]{$t_{max} = 8$, $\alpha = 10$, $\beta = 0.2$};
		\draw[yshift=\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=blue}] (0,0) node[right]{$t_{max} = 8$, ohne Optimierung};
		\draw[yshift=2\baselineskip] (0,0) -- 
			plot[mark=*, mark options={fill=red}] (0,0) node[right]{$t_{max} = 9$, ohne Optimierung};
		\end{scope}
	\end{tikzpicture}}
	\subfigure[\textit{CoolRandom}]{
	\begin{tikzpicture}
			\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={SSIM}, xlabel={in Grad}, xtick={0,5,10,20,...,90},
			 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
			 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]		
			\addplot[red, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D9L0.7I0.6pre.csv};
			\addplot[blue, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6pre.csv};		 
			\addplot[green, only marks, mark=x] table [x=a, y=m, col sep=comma] {div_data_mean_6_512x512D8L0.7I0.6A10.0J0.2pre.csv};
		
			\end{axis}
	\end{tikzpicture}}
	\caption{Vergleich zwischen nicht optimierten und einem optimiertem Netz.}
	\label{fig:eq_nvso}
\end{figure}

Die Abbildung \ref{fig:eq_nvso} zeigt die Güte von nicht nachbearbeiteten Netzen
im Vergleich zu einem optimierten Netz.
Dabei wurden die Parameter, wie zuvor $l = 0.7$ und $i = 0.6$ für alle Netze gewählt.
Es ist zu sehen, dass in der Szene \textit{TestSpheres} ein Kipppunkt existiert, 
bei dem das optimierte Netz besser als die anderen Netze abschneidet.
Ein solcher Kipppunkt existiert für \textit{CoolRandom} nicht.
Am Beispiel der \textit{TestSpheres}-Szene wird die Anzahl der erzeugten Dreiecke
verglichen.
Für $i_{max} = 9$ besteht das nicht optimierte Netz aus 7320 Dreiecken.
Wenn $i_{max} = 8$ ist, besteht das nicht nachbearbeitete Netz aus 3003 Dreiecken
und das optimierte Netz aus 4279 Dreiecken.

\begin{figure}
	\centering
	\subfigure[]{
	\begin{tikzpicture}[scale=0.9]
	\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in ms}, xlabel={Frame}, % xtick={0,5,10,20,...,90},
		 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
		 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	\addplot[black] table [x=i, y=d, col sep=comma]
	{div_duration_info_7_512x512Fd1631.0.csv};
	\addplot[green] table [x=i, y=min, col sep=comma]
	{div_duration_info_7_512x512Fd1631.0.csv};
	\addplot[red] table [x=i, y=max, col sep=comma]
	{div_duration_info_7_512x512Fd1631.0.csv};
	\addplot[blue] table [x=i, y=mean, col sep=comma]
	{div_duration_info_7_512x512Fd1631.0.csv};
	\end{axis}
	\end{tikzpicture}}
	\subfigure[]{
	\begin{tikzpicture}[scale=0.9]
	\begin{axis}[axis lines = middle, enlargelimits = true, ylabel={in ms}, xlabel={Frame}, % xtick={0,5,10,20,...,90},
	 every axis y label/.style={at={(ticklabel* cs:1.05)}, anchor=east},
	 every axis x label/.style={at={(ticklabel* cs:1.05)}, anchor=south}]
	\addplot[black] table [x=i, y=d, col sep=comma]
	{div_duration_info_6_512x512D10L0.0I0.0pre.csv};
	\addplot[green] table [x=i, y=min, col sep=comma]
	{div_duration_info_6_512x512D10L0.0I0.0pre.csv};
	\addplot[red] table [x=i, y=max, col sep=comma]
	{div_duration_info_6_512x512D10L0.0I0.0pre.csv};
	\addplot[blue] table [x=i, y=mean, col sep=comma]
	{div_duration_info_6_512x512D10L0.0I0.0pre.csv};
	\end{axis}
	\end{tikzpicture}}
	\caption{Die Diagramme stellen die Zeit, die der Client, zur Extrapolation
	der Frames benötigt grafisch dar. Dabei ist im Diagramm a die Vollvernetzung zu sehen und im Diagramm b die Delaunay-Triangulation.}
	\label{fig:data_client_extrapolation_time}
\end{figure}

Die Abbildung \ref{fig:data_client_extrapolation_time}, zeigt repräsentativ die Zeit die der Client für die Extrapolation benötigt.
Diese liegen sowohl für die Vollvernetzung als auch für die Delaunay-Triangulierung, im Schnitt unter einer Millisekunde.
Es gibt ein paar Ausreißer, die eine Zeit von 1.5 ms auch nicht überschreiten.

Im Folgenden werden die vorgestellten Ergebnisse diskutiert.

\chapter{Diskussion}

Das Ziel dieser Arbeit bestand darin, ein Verfahren zu entwickeln, das den Werteverlauf von Tiefenbildern, 
mit Hilfe von Dreiecksnetzen approximiert.

Zu diesen Zweck wurde die Vollvernetzung als Vergleichsmethode implementiert. 
Bei diesem Ansatz, werden die Tiefeninformationen aus dem Tiefenbild unverändert und 
unkomprimiert für die Bildextrapolation genutzt.
Sie liefert, wie es zu erwarten war die besten Ergebnisse für beide Szenen.
Zu erwähnen ist, dass die Ergebnisse in Abhängigkeit der gewählten Szene stark variieren.
Dies hängt damit zusammen, das die Szenen unterschiedlich beschaffen sind:
Die Szene \textit{TestSpheres} besteht aus wenigen großen Kugeln, mit großen Oberflächen
und wenigen Kanten,
wohingegen die Szene \textit{CoolRandom} aus vielen kleinen Kugeln, mit kleinen Oberflächen
und vielen Kanten besteht.

Zur Erfüllung der eigentlichen Aufgabe wurden zwei Verfahren, 
die auf der Delaunay-Triangulierung basieren, umgesetzt.
Die zur Vernetzung benötigte Punktmenge $P$, wird im ersten Ansatz mit einem \textit{Quadtree} erzeugt
und im Zweite nutzt wird die Floyd-Steinberg-Methode verwendet. 

Dabei liefert der \textit{Quadtree} weitaus bessere Resultate, als die FloydSteinberg-Methode.
Das Problem der FloydSteinberg-Methode besteht darin, das extrem viele Punkte vorwiegend in der Nähe von Kanten platziert werden.
Gekrümmte Oberflächen sind dagegen unterrepräsentiert.
Es werden aber insgesamt zu viele Punkte erzeugt, dadurch wird die Vernetzung langsam.
Außerdem enthält das resultierende Dreiecksnetz zu viele Dreiecke.

\begin{figure}
	\subfigure[$d_{max} = 10, l = 0.6, i = 0.3$]{\includegraphics[width=.3\textwidth]{img/delaunay_L06_I03.png}}
	\subfigure[$d_{max} = 9, l = 0.6, i = 0.3$]{\includegraphics[width=.3\textwidth]{img/delaunay9_L06_I03.png}}
	\subfigure[$d_{max} = 8, l = 0.6, i = 0.3$]{\includegraphics[width=.3\textwidth]{img/delaunay8_L06_I03.png}}
	
	\subfigure[$d_{max} = 10, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay_L07_I06.png}}
	\subfigure[$d_{max} = 9, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay9_L07_I06.png}}
	\subfigure[$d_{max} = 8, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay8_L07_I06.png}}
	\caption{Vergleich von Dreiecksnetzen, die mit dem \textit{Quadtree}-Ansatz erzeugt wurden.}
\end{figure}

\begin{figure}
	\subfigure[$d_{max} = 10, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay_L07_I06_100_02.png}}
	\subfigure[$d_{max} = 9, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay9_L07_I06_100_02.png}}
	\subfigure[$d_{max} = 8, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay8_L07_I06_100_02.png}}
	
	\subfigure[$d_{max} = 10, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay_L07_I06_100_02_f.png}}
	\subfigure[$d_{max} = 9, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay9_L07_I06_100_02_f.png}}
	\subfigure[$d_{max} = 8, l = 0.7, i = 0.6$]{\includegraphics[width=.3\textwidth]{img/delaunay8_L07_I06_100_02_f.png}}
	\caption{Vergleich von nachbearbeiteten Dreiecksnetzen, die mit dem \textit{Quadtree}-Ansatz erzeugt wurden. 
			 Dabei wurde $\alpha = 10$ und $\beta = 0.2$ gewählt.}
\end{figure}



Im Vergleich dazu schneidet der \textit{Quadtree}-Ansatz weitaus besser ab.
Weiterhin lässt sich die Qualität des resultierenden
Dreiecknetzes, mit dem Parameter $t_{max}$, adaptiv anpassen.
Große Werte für $t_{max}$ bedeuten in erster Linie,
das die Bereiche stärker unterteilt werden, sodass an markanten stellen, wie Kanten 
viele Punkte für die Vernetzung zur Verfügung stehen.
Das hat aber einen direkten Einfluss auf die Anzahl der Dreiecke und die Konstruktionsgeschwindigkeit.
Die Variablen $l$ und $i$ beeinflussen die Güte kaum, haben jedoch einen starken Einfluss auf die Anzahl der Dreiecke.
Nehmen $l$ und $i$ große Werte an, dann wird die Anzahl der Dreiecke reduziert.

Die Nachbearbeitung der Netze bringt grundsätzlich einen Gütezuwachs,
zulasten einer erhöhten Dreiecksanzahl.
Gleichzeitig entstehen Artefakte an den Rändern der Kugeln, 
wie in der Abbildung \ref{fig:refinementArtefakt} beispielhaft
zu erkennen ist.
Diese Artefakte in Form von Schnittkanten sorgen dafür, das die Güte
bei kleinen Kamerawinkelunterschieden im Vergleich zu nicht nachbearbeiteten Netzen
geringer ausfällt.
Wenn $\alpha$ Werte annimmt, die größer gleich als 10 sind, dann hat die Formel \ref{eq:EDGE_VALID}
keinen Einfluss auf das Ergebnisnetz.
Nimmt $\alpha$ Werte kleiner 10 an, dann werden Dreiecke innerhalb der Kugeln zusätzlich
unterteilt, was die Anzahl der Dreiecke insgesamt erhöht.
Allerdings gibt es in diesen Bereich bereits ausreichend viele Dreiecke um die Krümmung der Flächen
zu repräsentieren, sodass deren Unterteilung keinen messbaren Güteunterschied bewirkt.

Insgesamt, ist der beobachtete Geschwindigkeitsverlust, bei der Konstruktion der optimierten
Netze zu vernachlässigen, da die Nachbearbeitung für alle Dreiecke unabhängig voneinander berechnet
werden kann.
Diese Parallelisierung wurde in dieser Arbeit jedoch nicht implementiert.

\begin{figure}
	%\subfigure[]{\includegraphics[width=.3\textwidth]{img/frame_00002_A10_J01.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/frame_00002_A10_J01_n1.png}}
	\subfigure[]{\includegraphics[width=.49\textwidth]{img/frame_00002_A10_J01_n2.png}}
	\caption{Extrapolation des zweiten Frames, der Szene \textit{TestSpheres}.}
	\label{fig:refinementArtefakt}
\end{figure}

Aubfgrund der Messergebisse vom SSIM und dem PSNR lässt sich sagen, 
dass das Verfahren der Extrapolation durch die Rückprojektion
durchaus geeignet ist, um Bilder für kleine Kamerawinkelunterschiede von 5 bis 10 Grad ausreichend gut zu approximieren.
Dabei sind die Ergebnisse gemessen durch SSIM weitaus besser als die des PSNR,
sodass hier eine gute Approximation bis zu 20 Grad Winkelunterschied gewährleistet wird.
Dies ist positiv zu bewerten, da der SSIM im Gegensatz zum PSNR die menschliche Wahrnehmung mit einbezieht.

Ein grundsätzliches Problem der Extrapolation mit Hilfe der Rückprojektion, ist die Beleuchtung.
Insbesondere spekulare Lichtanteile sind ein Problem, weil diese von der Position der
Kamera abhängen.
Da das Farbbild als Textur dient und keine zusätzliche Beleuchtungsberechnung stattfindet,
entsteht zwangsläufig ein Fehler.
Dieser könnte dadurch reduziert werden, dass Informationen zu Lichtquellen mit übertragen
werden und eine clientseitige Nachbeleuchtung durchgeführt wird.
Das führt auf seiten des Clients zu erhöhten Berechnungskosten.
Ein anderer Ausweg könnte eine von der Kameraperspektive abhängigen Texturierung 
des Dreiecksnetzes sein. 
Zu diesem Zweck müssen aber zusätzliche Texturinformationen vom Server zum Client
übermittelt werden.
Desweiteren sind transparente Oberflächen problematisch.
Objekte die hinter diesen Oberflächen liegen, werden im Tiefenbild nicht repräsentiert.
Es entsteht auch hier ein Fehler bei der Extrapolation.

\begin{figure}
	\includegraphics[width=\textwidth]{../results/6/512x512_Delaunay/T0.8/G0.8/delaunay.png}
	\caption{FloydSteinberg-Ansatz mit den Parametern $\delta = 0.8, \gamma = 0.8$.}
\end{figure}

\chapter{Zusammenfassung und Ausblick}

In Rahmen dieser Arbeit wurde ein Remote-Visualisierungssystem konstruiert.
Mit diesem wurde untersucht, inwieweit die clientseitige Bildextrapolation,
mit Hilfe der Rückprojektion genutzt werden kann,
um die Latenzzeit vor dem Nutzer zu verbergen.
Zu diesem Zweck wurde das bei der Bildsynthese entstehende Tiefenbild
durch ein Dreiecksnetz approximiert und es wurde mit Hilfe
von \textit{Ground-Truth}-Datensätzen überprüft, 
bis zu welchem Kamerawinkelunterschied die Approximation akzeptable Ergebnisse
liefert. 
Das Hauptaugenmerk lag dabei in der Konstruktion der Dreiecksnetze.
Es hat sich gezeigt, dass die Delaunay-Triangulierung in Verbindung
mit einem \textit{Quadtree}-Ansatz diese Aufgabe erfüllt.
Die Komplexität des Dreiecknetzes lässt sich adaptiv anpassen.
Der Client ist in dadurch in der Lage Bilder bis zu einem Kamerawinkelunterschied
bis zu 20 Grad gut zu approximieren.

Im nächsten Schritt, kann die weitere Kompression der erzeugten Dreiecksnetze untersucht werden.
Desweiteren kann analysiert werden, inwiefern die extrapolierten Bilder zur Differenzbildkompression
genutzt werden können.

\nocite{*}
\end{document}